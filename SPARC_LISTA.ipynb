{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' # BE QUIET!!!! (info and warnings are not printed)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\" for 2080 Ti\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/saidinesh/.conda/envs/tensorflow-test/lib/python3.9/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf\n",
    "np.random.seed(1)\n",
    "tf.set_random_seed(1)\n",
    "from tools import problems,networks,train\n",
    "import math\n",
    "import sys\n",
    "import numpy.linalg as la\n",
    "\n",
    "from sparc_sim import sparc_sim\n",
    "from sparc_se import sparc_se\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ncode_params   = {'P': 15.0,    # Average codeword symbol power constraint\\n                 'R': 1.3,     # Rate\\n                 'L': 100,    # Number of sections\\n                 'M': 32}      # Columns per section\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "M = Number of columns in a section \n",
    "L = Number of section\n",
    "R = Rate\n",
    "pnz = sparsity\n",
    "awgn_var = AWGN channel variance\n",
    "\"\"\"\n",
    "\n",
    "P, M, L, R, pnz, awgn_var = 15, 32, 50, 0.5, 0.1, 0.01       #try with L=1000 sections later, changed R from 1.3 to 1.2\n",
    "K = 1    # for unmodulated case\n",
    "\n",
    "'''\n",
    "code_params   = {'P': 15.0,    # Average codeword symbol power constraint\n",
    "                 'R': 1.3,     # Rate\n",
    "                 'L': 100,    # Number of sections\n",
    "                 'M': 32}      # Columns per section\n",
    "'''                 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Message vector from bit stream "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minimum value for no_cols is 2 and should be even\n",
    "rng = np.random.RandomState(seed=None) \n",
    "\n",
    "def gen_msg(no_cols,M, L, K, R, rng):\n",
    "    #no_cols = 2000\n",
    "    colsby2 = int(np.divide(no_cols,2))\n",
    "\n",
    "    beta1 = np.zeros((L*M,colsby2))\n",
    "    beta_val = np.zeros((L*M, colsby2) )\n",
    "\n",
    "    bit_len = int(round(L*np.log2(K*M)))\n",
    "    logM = int(round(np.log2(M)))\n",
    "    sec_size = logM\n",
    "    L = bit_len // sec_size\n",
    "\n",
    "    W = np.array(P)\n",
    "\n",
    "    for i in range(1,no_cols):\n",
    "        #bit_len = int(round(L*np.log2(K*M)))   \n",
    "        bits_in = rng.randint(2, size=bit_len)  #generates a boolean vector of length 5000  (removed dtype=' bool')\n",
    "\n",
    "        beta0 = np.zeros(L*M)\n",
    "        for l in range(L):\n",
    "            bits_sec = bits_in[l*sec_size : l*sec_size + logM]\n",
    "            assert 0 < logM < 64\n",
    "            idx = bits_sec.dot(1 << np.arange(logM)[::-1])  # idx = decimal equivalent of the 5 bits (eg: 10100 will give 20)\n",
    "            beta0[l*M + idx] = 1      # will make a 1 at the decimal equivalent in the l-th section\n",
    "\n",
    "    # beta0 is a M*L length message vector that has 1 at decimal values of (5 bit stream) 32 length section.   \n",
    "\n",
    "        n = int(round(bit_len/R))\n",
    "        R_actual = bit_len / n      # Actual rate\n",
    "\n",
    "        #beta0 = beta0.reshape((L*M),1)\n",
    "        if i <= colsby2:\n",
    "            beta1[:,i-1] = beta0\n",
    "        else:\n",
    "            beta_val[:,i - no_cols] = beta0    \n",
    "\n",
    "    return beta1, beta_val, n, colsby2       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta1, beta_val, n, colsby2 = gen_msg(2000,M, L, K, R, rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.0\n"
     ]
    }
   ],
   "source": [
    "print(beta1[:,1].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Measurement Matrix\n",
    "Right now, we are working with Random i.i.d gaussian matrices with N(0,1/n). Later we may use FFT/DCT matrices for better computation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.random.normal(size=(n, L*M), scale=1.0 / math.sqrt(n)).astype(np.float32)\n",
    "A_ = tf.constant(A,name='A',dtype = tf.float32 )  #Made a tf constant since it need not be trained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "beta1 is for training, beta_val is for validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgen_ = tf.constant(beta1, dtype= tf.float32)  #changed to tf.constant\n",
    "#xgen_ = tf.cast(beta1, dtype= tf.float32)\n",
    "\n",
    "ygen_ = tf.matmul(A_,xgen_) + tf.random.normal( (n,colsby2),stddev=math.sqrt( awgn_var ) )\n",
    "y_val = np.matmul(A, beta_val) + np.random.normal( size = (n,colsby2),scale= math.sqrt(awgn_var)) #tf.sqrt(awgn_var)*rng.randn(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xgen_, ygen_ is given for training\n",
    "beta_val, y_val is for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const:0\", shape=(1600, 1000), dtype=float32)\n",
      "Tensor(\"add:0\", shape=(500, 1000), dtype=float32)\n",
      "Tensor(\"A:0\", shape=(500, 1600), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(xgen_)\n",
    "print(ygen_)\n",
    "print(A_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BUILD LISTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "T, initial_lambda = 6, 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_soft_threshold(r_, lam_):\n",
    "    \"implement a soft threshold function y=sign(r)*max(0,abs(r)-lam)\"\n",
    "    lam_ = tf.maximum(lam_, 0)\n",
    "    return tf.sign(r_) * tf.maximum(tf.abs(r_) - lam_, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating placeholders, which will hold dataset later.\n",
    "x_ = tf.compat.v1.placeholder( tf.float32,(L*M,None),name='x' )\n",
    "y_ = tf.compat.v1.placeholder( tf.float32,(n,None),name='y' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta = simple_soft_threshold #creating an object\n",
    "B = A.T / (1.01 * la.norm(A,2)**2) #(This is according to original code, not sure why)\n",
    "#B = A.T #numpy array\n",
    "\n",
    "# All of these below are tf, which means they will be stored as graphs and will run later. \n",
    "# B and S are the trainable parameters\n",
    "B_ = tf.Variable(B,dtype=tf.float32,name='B_0') #creating tf.variable to make it a trainable parameter. \n",
    "S_ = tf.Variable(np.identity(L*M) - np.matmul(B, A),dtype=tf.float32,name='S_0' )\n",
    "\n",
    "By_ = tf.matmul(B_,y_)  # This will be the input for the shrinkage function in the first iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'B_0:0' shape=(1600, 500) dtype=float32_ref>\n",
      "Tensor(\"MatMul_1:0\", shape=(1600, ?), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(B_)\n",
    "print(By_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not sure why it is written as a list. Might get clear later.\n",
    "layers = []\n",
    "layers.append( ('Linear',By_,None) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_lambda = np.array(initial_lambda).astype(np.float32)\n",
    "lam0_ = tf.Variable(initial_lambda,name='lam_0')  #to make it learnable\n",
    "\n",
    "xhat_ = eta( By_, lam0_) #first itertion and xhat_0 is all 0s\n",
    "layers.append( ('LISTA T=1',xhat_, (lam0_,) ) )\n",
    "\n",
    "for t in range(1,T):\n",
    "    lam_ = tf.Variable( initial_lambda,name='lam_{0}'.format(t) ) # using the same lambda\n",
    "    xhat_ = eta( tf.matmul(S_,xhat_) + By_, lam_ )  # will be stored as graphs which will run during a session later.   \n",
    "    layers.append( ('LISTA T='+str(t+1),xhat_,(lam_,)) ) # creating layers (xhat_ is an operation)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Linear', <tf.Tensor 'MatMul_1:0' shape=(1600, ?) dtype=float32>, None)\n",
      "('LISTA T=1', <tf.Tensor 'mul:0' shape=(1600, ?) dtype=float32>, (<tf.Variable 'lam_0:0' shape=() dtype=float32_ref>,))\n",
      "('LISTA T=2', <tf.Tensor 'mul_1:0' shape=(1600, ?) dtype=float32>, (<tf.Variable 'lam_1:0' shape=() dtype=float32_ref>,))\n",
      "('LISTA T=3', <tf.Tensor 'mul_2:0' shape=(1600, ?) dtype=float32>, (<tf.Variable 'lam_2:0' shape=() dtype=float32_ref>,))\n",
      "('LISTA T=4', <tf.Tensor 'mul_3:0' shape=(1600, ?) dtype=float32>, (<tf.Variable 'lam_3:0' shape=() dtype=float32_ref>,))\n",
      "('LISTA T=5', <tf.Tensor 'mul_4:0' shape=(1600, ?) dtype=float32>, (<tf.Variable 'lam_4:0' shape=() dtype=float32_ref>,))\n",
      "('LISTA T=6', <tf.Tensor 'mul_5:0' shape=(1600, ?) dtype=float32>, (<tf.Variable 'lam_5:0' shape=() dtype=float32_ref>,))\n",
      "<tf.Variable 'lam_0:0' shape=() dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "print(*layers , sep = \"\\n\")\n",
    "print(lam0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"MatMul_1:0\", shape=(1600, ?), dtype=float32)\n",
      "Tensor(\"mul:0\", shape=(1600, ?), dtype=float32)\n",
      "Tensor(\"mul_1:0\", shape=(1600, ?), dtype=float32)\n",
      "Tensor(\"mul_2:0\", shape=(1600, ?), dtype=float32)\n",
      "Tensor(\"mul_3:0\", shape=(1600, ?), dtype=float32)\n",
      "Tensor(\"mul_4:0\", shape=(1600, ?), dtype=float32)\n",
      "Tensor(\"mul_5:0\", shape=(1600, ?), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for name,xhat_,var_list in layers:\n",
    "    print(xhat_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Training LISTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "trinit,refinements,final_refine = 1e-3, (.5,.1,.01), None\n",
    "losses_=[]\n",
    "nmse_=[]\n",
    "trainers_=[]\n",
    "\n",
    "\"\"\"assert is used when, If the statement is true then it does nothing and continues \n",
    "the execution, but if the statement is False then it stops the execution of the program \n",
    "and throws an error.\n",
    "\"\"\"\n",
    "assert np.array(refinements).min()>0,'all refinements must be in (0,1]'\n",
    "assert np.array(refinements).max()<=1,'all refinements must be in (0,1]'\n",
    "\n",
    "tr_ = tf.Variable(trinit,name='tr',trainable=False) #Learning rate\n",
    "training_stages=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.disable_v2_behavior() #compatibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmse_denom_ = tf.nn.l2_loss(x_)  #computes half of l2 loss without the sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name,xhat_,var_list in layers:\n",
    "    loss_  = tf.nn.l2_loss( xhat_ - x_) #original values of x will be stored in the placeholder\n",
    "    nmse_  = tf.nn.l2_loss( (xhat_ - x_) ) / nmse_denom_ # computing the nmse.\n",
    "    if var_list is not None:\n",
    "            train_ = tf.train.AdamOptimizer(tr_).minimize(loss_, var_list=var_list) \n",
    "            training_stages.append( (name,xhat_,loss_,nmse_,train_,var_list) )\n",
    "    for fm in refinements:\n",
    "            train2_ = tf.train.AdamOptimizer(tr_*fm).minimize(loss_)\n",
    "            training_stages.append( (name+' trainrate=' + str(fm) ,xhat_,loss_,nmse_,train2_,()) )\n",
    "            \n",
    "if final_refine:\n",
    "    train2_ = tf.train.AdamOptimizer(tr_*final_refine).minimize(loss_)\n",
    "    training_stages.append( (name+' final refine ' + str(final_refine) ,xhat_,loss_,nmse_,train2_,()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Linear trainrate=0.5', <tf.Tensor 'MatMul_1:0' shape=(1600, ?) dtype=float32>, <tf.Tensor 'L2Loss_1:0' shape=() dtype=float32>, <tf.Tensor 'truediv:0' shape=() dtype=float32>, <tf.Operation 'Adam' type=NoOp>, ())\n",
      "('Linear trainrate=0.1', <tf.Tensor 'MatMul_1:0' shape=(1600, ?) dtype=float32>, <tf.Tensor 'L2Loss_1:0' shape=() dtype=float32>, <tf.Tensor 'truediv:0' shape=() dtype=float32>, <tf.Operation 'Adam_1' type=NoOp>, ())\n",
      "('Linear trainrate=0.01', <tf.Tensor 'MatMul_1:0' shape=(1600, ?) dtype=float32>, <tf.Tensor 'L2Loss_1:0' shape=() dtype=float32>, <tf.Tensor 'truediv:0' shape=() dtype=float32>, <tf.Operation 'Adam_2' type=NoOp>, ())\n",
      "('LISTA T=1', <tf.Tensor 'mul:0' shape=(1600, ?) dtype=float32>, <tf.Tensor 'L2Loss_3:0' shape=() dtype=float32>, <tf.Tensor 'truediv_1:0' shape=() dtype=float32>, <tf.Operation 'Adam_3' type=NoOp>, (<tf.Variable 'lam_0:0' shape=() dtype=float32_ref>,))\n",
      "('LISTA T=1 trainrate=0.5', <tf.Tensor 'mul:0' shape=(1600, ?) dtype=float32>, <tf.Tensor 'L2Loss_3:0' shape=() dtype=float32>, <tf.Tensor 'truediv_1:0' shape=() dtype=float32>, <tf.Operation 'Adam_4' type=NoOp>, ())\n",
      "('LISTA T=1 trainrate=0.1', <tf.Tensor 'mul:0' shape=(1600, ?) dtype=float32>, <tf.Tensor 'L2Loss_3:0' shape=() dtype=float32>, <tf.Tensor 'truediv_1:0' shape=() dtype=float32>, <tf.Operation 'Adam_5' type=NoOp>, ())\n",
      "('LISTA T=1 trainrate=0.01', <tf.Tensor 'mul:0' shape=(1600, ?) dtype=float32>, <tf.Tensor 'L2Loss_3:0' shape=() dtype=float32>, <tf.Tensor 'truediv_1:0' shape=() dtype=float32>, <tf.Operation 'Adam_6' type=NoOp>, ())\n",
      "('LISTA T=2', <tf.Tensor 'mul_1:0' shape=(1600, ?) dtype=float32>, <tf.Tensor 'L2Loss_5:0' shape=() dtype=float32>, <tf.Tensor 'truediv_2:0' shape=() dtype=float32>, <tf.Operation 'Adam_7' type=NoOp>, (<tf.Variable 'lam_1:0' shape=() dtype=float32_ref>,))\n",
      "('LISTA T=2 trainrate=0.5', <tf.Tensor 'mul_1:0' shape=(1600, ?) dtype=float32>, <tf.Tensor 'L2Loss_5:0' shape=() dtype=float32>, <tf.Tensor 'truediv_2:0' shape=() dtype=float32>, <tf.Operation 'Adam_8' type=NoOp>, ())\n",
      "('LISTA T=2 trainrate=0.1', <tf.Tensor 'mul_1:0' shape=(1600, ?) dtype=float32>, <tf.Tensor 'L2Loss_5:0' shape=() dtype=float32>, <tf.Tensor 'truediv_2:0' shape=() dtype=float32>, <tf.Operation 'Adam_9' type=NoOp>, ())\n",
      "('LISTA T=2 trainrate=0.01', <tf.Tensor 'mul_1:0' shape=(1600, ?) dtype=float32>, <tf.Tensor 'L2Loss_5:0' shape=() dtype=float32>, <tf.Tensor 'truediv_2:0' shape=() dtype=float32>, <tf.Operation 'Adam_10' type=NoOp>, ())\n",
      "('LISTA T=3', <tf.Tensor 'mul_2:0' shape=(1600, ?) dtype=float32>, <tf.Tensor 'L2Loss_7:0' shape=() dtype=float32>, <tf.Tensor 'truediv_3:0' shape=() dtype=float32>, <tf.Operation 'Adam_11' type=NoOp>, (<tf.Variable 'lam_2:0' shape=() dtype=float32_ref>,))\n",
      "('LISTA T=3 trainrate=0.5', <tf.Tensor 'mul_2:0' shape=(1600, ?) dtype=float32>, <tf.Tensor 'L2Loss_7:0' shape=() dtype=float32>, <tf.Tensor 'truediv_3:0' shape=() dtype=float32>, <tf.Operation 'Adam_12' type=NoOp>, ())\n",
      "('LISTA T=3 trainrate=0.1', <tf.Tensor 'mul_2:0' shape=(1600, ?) dtype=float32>, <tf.Tensor 'L2Loss_7:0' shape=() dtype=float32>, <tf.Tensor 'truediv_3:0' shape=() dtype=float32>, <tf.Operation 'Adam_13' type=NoOp>, ())\n",
      "('LISTA T=3 trainrate=0.01', <tf.Tensor 'mul_2:0' shape=(1600, ?) dtype=float32>, <tf.Tensor 'L2Loss_7:0' shape=() dtype=float32>, <tf.Tensor 'truediv_3:0' shape=() dtype=float32>, <tf.Operation 'Adam_14' type=NoOp>, ())\n",
      "('LISTA T=4', <tf.Tensor 'mul_3:0' shape=(1600, ?) dtype=float32>, <tf.Tensor 'L2Loss_9:0' shape=() dtype=float32>, <tf.Tensor 'truediv_4:0' shape=() dtype=float32>, <tf.Operation 'Adam_15' type=NoOp>, (<tf.Variable 'lam_3:0' shape=() dtype=float32_ref>,))\n",
      "('LISTA T=4 trainrate=0.5', <tf.Tensor 'mul_3:0' shape=(1600, ?) dtype=float32>, <tf.Tensor 'L2Loss_9:0' shape=() dtype=float32>, <tf.Tensor 'truediv_4:0' shape=() dtype=float32>, <tf.Operation 'Adam_16' type=NoOp>, ())\n",
      "('LISTA T=4 trainrate=0.1', <tf.Tensor 'mul_3:0' shape=(1600, ?) dtype=float32>, <tf.Tensor 'L2Loss_9:0' shape=() dtype=float32>, <tf.Tensor 'truediv_4:0' shape=() dtype=float32>, <tf.Operation 'Adam_17' type=NoOp>, ())\n",
      "('LISTA T=4 trainrate=0.01', <tf.Tensor 'mul_3:0' shape=(1600, ?) dtype=float32>, <tf.Tensor 'L2Loss_9:0' shape=() dtype=float32>, <tf.Tensor 'truediv_4:0' shape=() dtype=float32>, <tf.Operation 'Adam_18' type=NoOp>, ())\n",
      "('LISTA T=5', <tf.Tensor 'mul_4:0' shape=(1600, ?) dtype=float32>, <tf.Tensor 'L2Loss_11:0' shape=() dtype=float32>, <tf.Tensor 'truediv_5:0' shape=() dtype=float32>, <tf.Operation 'Adam_19' type=NoOp>, (<tf.Variable 'lam_4:0' shape=() dtype=float32_ref>,))\n",
      "('LISTA T=5 trainrate=0.5', <tf.Tensor 'mul_4:0' shape=(1600, ?) dtype=float32>, <tf.Tensor 'L2Loss_11:0' shape=() dtype=float32>, <tf.Tensor 'truediv_5:0' shape=() dtype=float32>, <tf.Operation 'Adam_20' type=NoOp>, ())\n",
      "('LISTA T=5 trainrate=0.1', <tf.Tensor 'mul_4:0' shape=(1600, ?) dtype=float32>, <tf.Tensor 'L2Loss_11:0' shape=() dtype=float32>, <tf.Tensor 'truediv_5:0' shape=() dtype=float32>, <tf.Operation 'Adam_21' type=NoOp>, ())\n",
      "('LISTA T=5 trainrate=0.01', <tf.Tensor 'mul_4:0' shape=(1600, ?) dtype=float32>, <tf.Tensor 'L2Loss_11:0' shape=() dtype=float32>, <tf.Tensor 'truediv_5:0' shape=() dtype=float32>, <tf.Operation 'Adam_22' type=NoOp>, ())\n",
      "('LISTA T=6', <tf.Tensor 'mul_5:0' shape=(1600, ?) dtype=float32>, <tf.Tensor 'L2Loss_13:0' shape=() dtype=float32>, <tf.Tensor 'truediv_6:0' shape=() dtype=float32>, <tf.Operation 'Adam_23' type=NoOp>, (<tf.Variable 'lam_5:0' shape=() dtype=float32_ref>,))\n",
      "('LISTA T=6 trainrate=0.5', <tf.Tensor 'mul_5:0' shape=(1600, ?) dtype=float32>, <tf.Tensor 'L2Loss_13:0' shape=() dtype=float32>, <tf.Tensor 'truediv_6:0' shape=() dtype=float32>, <tf.Operation 'Adam_24' type=NoOp>, ())\n",
      "('LISTA T=6 trainrate=0.1', <tf.Tensor 'mul_5:0' shape=(1600, ?) dtype=float32>, <tf.Tensor 'L2Loss_13:0' shape=() dtype=float32>, <tf.Tensor 'truediv_6:0' shape=() dtype=float32>, <tf.Operation 'Adam_25' type=NoOp>, ())\n",
      "('LISTA T=6 trainrate=0.01', <tf.Tensor 'mul_5:0' shape=(1600, ?) dtype=float32>, <tf.Tensor 'L2Loss_13:0' shape=() dtype=float32>, <tf.Tensor 'truediv_6:0' shape=() dtype=float32>, <tf.Operation 'Adam_26' type=NoOp>, ())\n"
     ]
    }
   ],
   "source": [
    "print(*training_stages , sep = \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do training LISTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_trainable_vars(sess,filename,**kwargs):\n",
    "    \"\"\"save a .npz archive in `filename`  with\n",
    "    the current value of each variable in tf.trainable_variables()\n",
    "    plus any keyword numpy arrays.\n",
    "    \"\"\"\n",
    "    save={}\n",
    "    for v in tf.trainable_variables():\n",
    "        save[str(v.name)] = sess.run(v)\n",
    "    save.update(kwargs)\n",
    "    np.savez(filename,**save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_trainable_vars(sess,filename):\n",
    "    \"\"\"load a .npz archive and assign the value of each loaded\n",
    "    ndarray to the trainable variable whose name matches the\n",
    "    archive key.  Any elements in the archive that do not have\n",
    "    a corresponding trainable variable will be returned in a dict.\n",
    "    \"\"\"\n",
    "    other={}\n",
    "    try:\n",
    "        tv=dict([ (str(v.name),v) for v in tf.trainable_variables() ])\n",
    "        for k,d in np.load(filename).items():\n",
    "            if k in tv:\n",
    "                print('restoring ' + k)\n",
    "                sess.run(tf.assign( tv[k], d) )\n",
    "            else:\n",
    "                other[k] = d\n",
    "    except IOError:\n",
    "        pass\n",
    "    return other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "naming convention:\n",
    "LISTA_SPARC_layers_rate_awgn_var.npz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[1600,500] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node B_0/Adam_28/Assign (defined at tmp/ipykernel_504184/1593469415.py:8) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nOriginal stack trace for 'B_0/Adam_28/Assign':\n  File \"home/saidinesh/.conda/envs/tensorflow-test/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"home/saidinesh/.conda/envs/tensorflow-test/lib/python3.9/runpy.py\", line 87, in _run_code\n    exec(code, run_globals)\n  File \"home/saidinesh/.conda/envs/tensorflow-test/lib/python3.9/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"home/saidinesh/.conda/envs/tensorflow-test/lib/python3.9/site-packages/traitlets/config/application.py\", line 846, in launch_instance\n    app.start()\n  File \"home/saidinesh/.conda/envs/tensorflow-test/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 677, in start\n    self.io_loop.start()\n  File \"home/saidinesh/.conda/envs/tensorflow-test/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 199, in start\n    self.asyncio_loop.run_forever()\n  File \"home/saidinesh/.conda/envs/tensorflow-test/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n    self._run_once()\n  File \"home/saidinesh/.conda/envs/tensorflow-test/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n    handle._run()\n  File \"home/saidinesh/.conda/envs/tensorflow-test/lib/python3.9/asyncio/events.py\", line 80, in _run\n    self._context.run(self._callback, *self._args)\n  File \"home/saidinesh/.conda/envs/tensorflow-test/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 471, in dispatch_queue\n    await self.process_one()\n  File \"home/saidinesh/.conda/envs/tensorflow-test/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 460, in process_one\n    await dispatch(*args)\n  File \"home/saidinesh/.conda/envs/tensorflow-test/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 367, in dispatch_shell\n    await result\n  File \"home/saidinesh/.conda/envs/tensorflow-test/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 662, in execute_request\n    reply_content = await reply_content\n  File \"home/saidinesh/.conda/envs/tensorflow-test/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 360, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"home/saidinesh/.conda/envs/tensorflow-test/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 532, in run_cell\n    return super().run_cell(*args, **kwargs)\n  File \"home/saidinesh/.conda/envs/tensorflow-test/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2880, in run_cell\n    result = self._run_cell(\n  File \"home/saidinesh/.conda/envs/tensorflow-test/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2935, in _run_cell\n    return runner(coro)\n  File \"home/saidinesh/.conda/envs/tensorflow-test/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n    coro.send(None)\n  File \"home/saidinesh/.conda/envs/tensorflow-test/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3134, in run_cell_async\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n  File \"home/saidinesh/.conda/envs/tensorflow-test/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3337, in run_ast_nodes\n    if await self.run_code(code, result, async_=asy):\n  File \"home/saidinesh/.conda/envs/tensorflow-test/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3397, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"tmp/ipykernel_504184/1593469415.py\", line 8, in <cell line: 1>\n    train2_ = tf.train.AdamOptimizer(tr_*fm).minimize(loss_)\n  File \"home/saidinesh/.conda/envs/tensorflow-test/lib/python3.9/site-packages/tensorflow/python/training/optimizer.py\", line 412, in minimize\n    return self.apply_gradients(grads_and_vars, global_step=global_step,\n  File \"home/saidinesh/.conda/envs/tensorflow-test/lib/python3.9/site-packages/tensorflow/python/training/optimizer.py\", line 597, in apply_gradients\n    self._create_slots(var_list)\n  File \"home/saidinesh/.conda/envs/tensorflow-test/lib/python3.9/site-packages/tensorflow/python/training/adam.py\", line 138, in _create_slots\n    self._zeros_slot(v, \"m\", self._name)\n  File \"home/saidinesh/.conda/envs/tensorflow-test/lib/python3.9/site-packages/tensorflow/python/training/optimizer.py\", line 1158, in _zeros_slot\n    new_slot_variable = slot_creator.create_zeros_slot(var, op_name)\n  File \"home/saidinesh/.conda/envs/tensorflow-test/lib/python3.9/site-packages/tensorflow/python/training/slot_creator.py\", line 195, in create_zeros_slot\n    return create_slot_with_initializer(\n  File \"home/saidinesh/.conda/envs/tensorflow-test/lib/python3.9/site-packages/tensorflow/python/training/slot_creator.py\", line 170, in create_slot_with_initializer\n    return _create_slot_var(primary, initializer, \"\", validate_shape, shape,\n  File \"home/saidinesh/.conda/envs/tensorflow-test/lib/python3.9/site-packages/tensorflow/python/training/slot_creator.py\", line 66, in _create_slot_var\n    slot = variable_scope.get_variable(\n  File \"home/saidinesh/.conda/envs/tensorflow-test/lib/python3.9/site-packages/tensorflow/python/ops/variable_scope.py\", line 1577, in get_variable\n    return get_variable_scope().get_variable(\n  File \"home/saidinesh/.conda/envs/tensorflow-test/lib/python3.9/site-packages/tensorflow/python/ops/variable_scope.py\", line 1320, in get_variable\n    return var_store.get_variable(\n  File \"home/saidinesh/.conda/envs/tensorflow-test/lib/python3.9/site-packages/tensorflow/python/ops/variable_scope.py\", line 576, in get_variable\n    return _true_getter(\n  File \"home/saidinesh/.conda/envs/tensorflow-test/lib/python3.9/site-packages/tensorflow/python/ops/variable_scope.py\", line 529, in _true_getter\n    return self._get_single_variable(\n  File \"home/saidinesh/.conda/envs/tensorflow-test/lib/python3.9/site-packages/tensorflow/python/ops/variable_scope.py\", line 950, in _get_single_variable\n    v = variables.VariableV1(\n  File \"home/saidinesh/.conda/envs/tensorflow-test/lib/python3.9/site-packages/tensorflow/python/ops/variables.py\", line 260, in __call__\n    return cls._variable_v1_call(*args, **kwargs)\n  File \"home/saidinesh/.conda/envs/tensorflow-test/lib/python3.9/site-packages/tensorflow/python/ops/variables.py\", line 206, in _variable_v1_call\n    return previous_getter(\n  File \"home/saidinesh/.conda/envs/tensorflow-test/lib/python3.9/site-packages/tensorflow/python/ops/variables.py\", line 199, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"home/saidinesh/.conda/envs/tensorflow-test/lib/python3.9/site-packages/tensorflow/python/ops/variable_scope.py\", line 2620, in default_variable_creator\n    return variables.RefVariable(\n  File \"home/saidinesh/.conda/envs/tensorflow-test/lib/python3.9/site-packages/tensorflow/python/ops/variables.py\", line 264, in __call__\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n  File \"home/saidinesh/.conda/envs/tensorflow-test/lib/python3.9/site-packages/tensorflow/python/ops/variables.py\", line 1656, in __init__\n    self._init_from_args(\n  File \"home/saidinesh/.conda/envs/tensorflow-test/lib/python3.9/site-packages/tensorflow/python/ops/variables.py\", line 1847, in _init_from_args\n    self._initializer_op = state_ops.assign(\n  File \"home/saidinesh/.conda/envs/tensorflow-test/lib/python3.9/site-packages/tensorflow/python/ops/state_ops.py\", line 225, in assign\n    return gen_state_ops.assign(\n  File \"home/saidinesh/.conda/envs/tensorflow-test/lib/python3.9/site-packages/tensorflow/python/ops/gen_state_ops.py\", line 58, in assign\n    _, _, _op, _outputs = _op_def_library._apply_op_helper(\n  File \"home/saidinesh/.conda/envs/tensorflow-test/lib/python3.9/site-packages/tensorflow/python/framework/op_def_library.py\", line 748, in _apply_op_helper\n    op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n  File \"home/saidinesh/.conda/envs/tensorflow-test/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 3528, in _create_op_internal\n    ret = Operation(\n  File \"home/saidinesh/.conda/envs/tensorflow-test/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 1990, in __init__\n    self._traceback = tf_stack.extract_stack()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "File \u001b[0;32m~/.conda/envs/tensorflow-test/lib/python3.9/site-packages/tensorflow/python/client/session.py:1375\u001b[0m, in \u001b[0;36mBaseSession._do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1374\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1375\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs)\n\u001b[1;32m   1376\u001b[0m \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mOpError \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.conda/envs/tensorflow-test/lib/python3.9/site-packages/tensorflow/python/client/session.py:1359\u001b[0m, in \u001b[0;36mBaseSession._do_run.<locals>._run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1358\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_extend_graph()\n\u001b[0;32m-> 1359\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[1;32m   1360\u001b[0m                                 target_list, run_metadata)\n",
      "File \u001b[0;32m~/.conda/envs/tensorflow-test/lib/python3.9/site-packages/tensorflow/python/client/session.py:1451\u001b[0m, in \u001b[0;36mBaseSession._call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1449\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call_tf_sessionrun\u001b[39m(\u001b[39mself\u001b[39m, options, feed_dict, fetch_list, target_list,\n\u001b[1;32m   1450\u001b[0m                         run_metadata):\n\u001b[0;32m-> 1451\u001b[0m   \u001b[39mreturn\u001b[39;00m tf_session\u001b[39m.\u001b[39;49mTF_SessionRun_wrapper(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_session, options, feed_dict,\n\u001b[1;32m   1452\u001b[0m                                           fetch_list, target_list,\n\u001b[1;32m   1453\u001b[0m                                           run_metadata)\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[1600,500] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node B_0/Adam_28/Assign}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m/home/saidinesh/sparc_public-master/SPARC_LISTA.ipynb Cell 35\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.21.1.179/home/saidinesh/sparc_public-master/SPARC_LISTA.ipynb#X46sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m ivl, maxit, better_wait \u001b[39m=\u001b[39m\u001b[39m10\u001b[39m,\u001b[39m1000000\u001b[39m,\u001b[39m3000\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.21.1.179/home/saidinesh/sparc_public-master/SPARC_LISTA.ipynb#X46sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m sess \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mSession()\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B10.21.1.179/home/saidinesh/sparc_public-master/SPARC_LISTA.ipynb#X46sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m sess\u001b[39m.\u001b[39;49mrun(tf\u001b[39m.\u001b[39;49mglobal_variables_initializer())\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.21.1.179/home/saidinesh/sparc_public-master/SPARC_LISTA.ipynb#X46sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mnorms xval:\u001b[39m\u001b[39m{xval:.7f}\u001b[39;00m\u001b[39m yval:\u001b[39m\u001b[39m{yval:.7f}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(xval\u001b[39m=\u001b[39mla\u001b[39m.\u001b[39mnorm(beta_val), yval\u001b[39m=\u001b[39mla\u001b[39m.\u001b[39mnorm(y_val) ) )\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.21.1.179/home/saidinesh/sparc_public-master/SPARC_LISTA.ipynb#X46sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m state \u001b[39m=\u001b[39m load_trainable_vars(sess,\u001b[39m'\u001b[39m\u001b[39mLISTA_SPARC_6_R0p5_01.npz\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m# must load AFTER the initializer\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/tensorflow-test/lib/python3.9/site-packages/tensorflow/python/client/session.py:967\u001b[0m, in \u001b[0;36mBaseSession.run\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    964\u001b[0m run_metadata_ptr \u001b[39m=\u001b[39m tf_session\u001b[39m.\u001b[39mTF_NewBuffer() \u001b[39mif\u001b[39;00m run_metadata \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    966\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 967\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(\u001b[39mNone\u001b[39;49;00m, fetches, feed_dict, options_ptr,\n\u001b[1;32m    968\u001b[0m                      run_metadata_ptr)\n\u001b[1;32m    969\u001b[0m   \u001b[39mif\u001b[39;00m run_metadata:\n\u001b[1;32m    970\u001b[0m     proto_data \u001b[39m=\u001b[39m tf_session\u001b[39m.\u001b[39mTF_GetBuffer(run_metadata_ptr)\n",
      "File \u001b[0;32m~/.conda/envs/tensorflow-test/lib/python3.9/site-packages/tensorflow/python/client/session.py:1190\u001b[0m, in \u001b[0;36mBaseSession._run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# We only want to really perform the run if fetches or targets are provided,\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39m# or if the call is a partial run that specifies feeds.\u001b[39;00m\n\u001b[1;32m   1189\u001b[0m \u001b[39mif\u001b[39;00m final_fetches \u001b[39mor\u001b[39;00m final_targets \u001b[39mor\u001b[39;00m (handle \u001b[39mand\u001b[39;00m feed_dict_tensor):\n\u001b[0;32m-> 1190\u001b[0m   results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_run(handle, final_targets, final_fetches,\n\u001b[1;32m   1191\u001b[0m                          feed_dict_tensor, options, run_metadata)\n\u001b[1;32m   1192\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1193\u001b[0m   results \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/.conda/envs/tensorflow-test/lib/python3.9/site-packages/tensorflow/python/client/session.py:1368\u001b[0m, in \u001b[0;36mBaseSession._do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1365\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_tf_sessionprun(handle, feed_dict, fetch_list)\n\u001b[1;32m   1367\u001b[0m \u001b[39mif\u001b[39;00m handle \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1368\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m   1369\u001b[0m                        run_metadata)\n\u001b[1;32m   1370\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1371\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_do_call(_prun_fn, handle, feeds, fetches)\n",
      "File \u001b[0;32m~/.conda/envs/tensorflow-test/lib/python3.9/site-packages/tensorflow/python/client/session.py:1394\u001b[0m, in \u001b[0;36mBaseSession._do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1389\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39monly supports NHWC tensor format\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m message:\n\u001b[1;32m   1390\u001b[0m   message \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mA possible workaround: Try disabling Grappler optimizer\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   1391\u001b[0m               \u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mby modifying the config for creating the session eg.\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   1392\u001b[0m               \u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39msession_config.graph_options.rewrite_options.\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   1393\u001b[0m               \u001b[39m'\u001b[39m\u001b[39mdisable_meta_optimizer = True\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m-> 1394\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mtype\u001b[39m(e)(node_def, op, message)\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[1600,500] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node B_0/Adam_28/Assign (defined at tmp/ipykernel_504184/1593469415.py:8) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nOriginal stack trace for 'B_0/Adam_28/Assign':\n  File \"home/saidinesh/.conda/envs/tensorflow-test/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"home/saidinesh/.conda/envs/tensorflow-test/lib/python3.9/runpy.py\", line 87, in _run_code\n    exec(code, run_globals)\n  File \"home/saidinesh/.conda/envs/tensorflow-test/lib/python3.9/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"home/saidinesh/.conda/envs/tensorflow-test/lib/python3.9/site-packages/traitlets/config/application.py\", line 846, in launch_instance\n    app.start()\n  File \"home/saidinesh/.conda/envs/tensorflow-test/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 677, in start\n    self.io_loop.start()\n  File \"home/saidinesh/.conda/envs/tensorflow-test/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 199, in start\n    self.asyncio_loop.run_forever()\n  File \"home/saidinesh/.conda/envs/tensorflow-test/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n    self._run_once()\n  File \"home/saidinesh/.conda/envs/tensorflow-test/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n    handle._run()\n  File \"home/saidinesh/.conda/envs/tensorflow-test/lib/python3.9/asyncio/events.py\", line 80, in _run\n    self._context.run(self._callback, *self._args)\n  File \"home/saidinesh/.conda/envs/tensorflow-test/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 471, in dispatch_queue\n    await self.process_one()\n  File \"home/saidinesh/.conda/envs/tensorflow-test/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 460, in process_one\n    await dispatch(*args)\n  File \"home/saidinesh/.conda/envs/tensorflow-test/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 367, in dispatch_shell\n    await result\n  File \"home/saidinesh/.conda/envs/tensorflow-test/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 662, in execute_request\n    reply_content = await reply_content\n  File \"home/saidinesh/.conda/envs/tensorflow-test/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 360, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"home/saidinesh/.conda/envs/tensorflow-test/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 532, in run_cell\n    return super().run_cell(*args, **kwargs)\n  File \"home/saidinesh/.conda/envs/tensorflow-test/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2880, in run_cell\n    result = self._run_cell(\n  File \"home/saidinesh/.conda/envs/tensorflow-test/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2935, in _run_cell\n    return runner(coro)\n  File \"home/saidinesh/.conda/envs/tensorflow-test/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n    coro.send(None)\n  File \"home/saidinesh/.conda/envs/tensorflow-test/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3134, in run_cell_async\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n  File \"home/saidinesh/.conda/envs/tensorflow-test/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3337, in run_ast_nodes\n    if await self.run_code(code, result, async_=asy):\n  File \"home/saidinesh/.conda/envs/tensorflow-test/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3397, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"tmp/ipykernel_504184/1593469415.py\", line 8, in <cell line: 1>\n    train2_ = tf.train.AdamOptimizer(tr_*fm).minimize(loss_)\n  File \"home/saidinesh/.conda/envs/tensorflow-test/lib/python3.9/site-packages/tensorflow/python/training/optimizer.py\", line 412, in minimize\n    return self.apply_gradients(grads_and_vars, global_step=global_step,\n  File \"home/saidinesh/.conda/envs/tensorflow-test/lib/python3.9/site-packages/tensorflow/python/training/optimizer.py\", line 597, in apply_gradients\n    self._create_slots(var_list)\n  File \"home/saidinesh/.conda/envs/tensorflow-test/lib/python3.9/site-packages/tensorflow/python/training/adam.py\", line 138, in _create_slots\n    self._zeros_slot(v, \"m\", self._name)\n  File \"home/saidinesh/.conda/envs/tensorflow-test/lib/python3.9/site-packages/tensorflow/python/training/optimizer.py\", line 1158, in _zeros_slot\n    new_slot_variable = slot_creator.create_zeros_slot(var, op_name)\n  File \"home/saidinesh/.conda/envs/tensorflow-test/lib/python3.9/site-packages/tensorflow/python/training/slot_creator.py\", line 195, in create_zeros_slot\n    return create_slot_with_initializer(\n  File \"home/saidinesh/.conda/envs/tensorflow-test/lib/python3.9/site-packages/tensorflow/python/training/slot_creator.py\", line 170, in create_slot_with_initializer\n    return _create_slot_var(primary, initializer, \"\", validate_shape, shape,\n  File \"home/saidinesh/.conda/envs/tensorflow-test/lib/python3.9/site-packages/tensorflow/python/training/slot_creator.py\", line 66, in _create_slot_var\n    slot = variable_scope.get_variable(\n  File \"home/saidinesh/.conda/envs/tensorflow-test/lib/python3.9/site-packages/tensorflow/python/ops/variable_scope.py\", line 1577, in get_variable\n    return get_variable_scope().get_variable(\n  File \"home/saidinesh/.conda/envs/tensorflow-test/lib/python3.9/site-packages/tensorflow/python/ops/variable_scope.py\", line 1320, in get_variable\n    return var_store.get_variable(\n  File \"home/saidinesh/.conda/envs/tensorflow-test/lib/python3.9/site-packages/tensorflow/python/ops/variable_scope.py\", line 576, in get_variable\n    return _true_getter(\n  File \"home/saidinesh/.conda/envs/tensorflow-test/lib/python3.9/site-packages/tensorflow/python/ops/variable_scope.py\", line 529, in _true_getter\n    return self._get_single_variable(\n  File \"home/saidinesh/.conda/envs/tensorflow-test/lib/python3.9/site-packages/tensorflow/python/ops/variable_scope.py\", line 950, in _get_single_variable\n    v = variables.VariableV1(\n  File \"home/saidinesh/.conda/envs/tensorflow-test/lib/python3.9/site-packages/tensorflow/python/ops/variables.py\", line 260, in __call__\n    return cls._variable_v1_call(*args, **kwargs)\n  File \"home/saidinesh/.conda/envs/tensorflow-test/lib/python3.9/site-packages/tensorflow/python/ops/variables.py\", line 206, in _variable_v1_call\n    return previous_getter(\n  File \"home/saidinesh/.conda/envs/tensorflow-test/lib/python3.9/site-packages/tensorflow/python/ops/variables.py\", line 199, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"home/saidinesh/.conda/envs/tensorflow-test/lib/python3.9/site-packages/tensorflow/python/ops/variable_scope.py\", line 2620, in default_variable_creator\n    return variables.RefVariable(\n  File \"home/saidinesh/.conda/envs/tensorflow-test/lib/python3.9/site-packages/tensorflow/python/ops/variables.py\", line 264, in __call__\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n  File \"home/saidinesh/.conda/envs/tensorflow-test/lib/python3.9/site-packages/tensorflow/python/ops/variables.py\", line 1656, in __init__\n    self._init_from_args(\n  File \"home/saidinesh/.conda/envs/tensorflow-test/lib/python3.9/site-packages/tensorflow/python/ops/variables.py\", line 1847, in _init_from_args\n    self._initializer_op = state_ops.assign(\n  File \"home/saidinesh/.conda/envs/tensorflow-test/lib/python3.9/site-packages/tensorflow/python/ops/state_ops.py\", line 225, in assign\n    return gen_state_ops.assign(\n  File \"home/saidinesh/.conda/envs/tensorflow-test/lib/python3.9/site-packages/tensorflow/python/ops/gen_state_ops.py\", line 58, in assign\n    _, _, _op, _outputs = _op_def_library._apply_op_helper(\n  File \"home/saidinesh/.conda/envs/tensorflow-test/lib/python3.9/site-packages/tensorflow/python/framework/op_def_library.py\", line 748, in _apply_op_helper\n    op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n  File \"home/saidinesh/.conda/envs/tensorflow-test/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 3528, in _create_op_internal\n    ret = Operation(\n  File \"home/saidinesh/.conda/envs/tensorflow-test/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 1990, in __init__\n    self._traceback = tf_stack.extract_stack()\n"
     ]
    }
   ],
   "source": [
    "ivl, maxit, better_wait =10,1000000,3000\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "print('norms xval:{xval:.7f} yval:{yval:.7f}'.format(xval=la.norm(beta_val), yval=la.norm(y_val) ) )\n",
    "\n",
    "state = load_trainable_vars(sess,'LISTA_SPARC_6_R0p5_01.npz') # must load AFTER the initializer\n",
    "\n",
    "    # must use this same Session to perform all training\n",
    "    # if we start a new Session, things would replay and we'd be training with our validation set (no no)\n",
    "\n",
    "done=state.get('done',[])\n",
    "log=str(state.get('log',''))\n",
    "\n",
    "for name,xhat_,loss_,nmse_,train_,var_list in training_stages:\n",
    "    if name in done:\n",
    "        print('Already did ' + name + '. Skipping.')\n",
    "        continue\n",
    "    if len(var_list):\n",
    "        describe_var_list = 'extending ' + ','.join([v.name for v in var_list])\n",
    "    else:\n",
    "        describe_var_list = 'fine tuning all ' + ','.join([v.name for v in tf.trainable_variables() ])\n",
    "\n",
    "    print(name + ' ' + describe_var_list)\n",
    "    nmse_history=[]\n",
    "    for i in range(maxit+1):\n",
    "        if i%ivl == 0:\n",
    "            nmse = sess.run(nmse_,feed_dict={y_:y_val,x_:beta_val})\n",
    "            if np.isnan(nmse):\n",
    "                raise RuntimeError('nmse is NaN')\n",
    "            nmse_history = np.append(nmse_history,nmse)\n",
    "            nmse_dB = 10*np.log10(nmse)\n",
    "            nmsebest_dB = 10*np.log10(nmse_history.min())\n",
    "            sys.stdout.write('\\ri={i:<6d} nmse={nmse:.6f} dB (best={best:.6f})'.format(i=i,nmse=nmse_dB,best=nmsebest_dB))\n",
    "            sys.stdout.flush()\n",
    "            if i%(100*ivl) == 0:\n",
    "                print('')\n",
    "                age_of_best = len(nmse_history) - nmse_history.argmin()-1 # how long ago was the best nmse?\n",
    "                if age_of_best*ivl > better_wait:\n",
    "                    break # if it has not improved on the best answer for quite some time, then move along\n",
    "        #y,x = prob(sess)\n",
    "        y, x= sess.run( ( ygen_,xgen_ ) ) # generates different y,x for every iteration.\n",
    "        sess.run(train_,feed_dict={y_:y,x_:x} )\n",
    "    done = np.append(done,name)\n",
    "\n",
    "    log =  log+'\\n{name} nmse={nmse:.6f} dB in {i} iterations'.format(name=name,nmse=nmse_dB,i=i)\n",
    "\n",
    "    state['done'] = done\n",
    "    state['log'] = log\n",
    "    save_trainable_vars(sess,'LISTA_SPARC_6_R0p5_01.npz',**state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_test, beta_test2, n, colsby2_test = gen_msg(2,M, L, K, R, rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.matmul(A, beta_test) + np.random.normal( size = (n,colsby2_test),scale= math.sqrt(awgn_var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for name,xhat_,var_list in layers:\n",
    "    count = count + 1\n",
    "    if count != T+1:\n",
    "        continue\n",
    "    else:\n",
    "        out = sess.run(xhat_,feed_dict={y_:y_test,x_:beta_test})\n",
    "    #if count == 2:\n",
    "    #    out = sess.run(xhat_,feed_dict={y_:y_test,x_:beta_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xtest= \n",
      " [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " ...\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "estimated out \n",
      " [[ 0.3396565 ]\n",
      " [ 0.22745505]\n",
      " [-0.6091439 ]\n",
      " ...\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [ 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print('xtest= \\n',beta_test)\n",
    "print('estimated out \\n', out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.0\n",
      "-11.148475\n"
     ]
    }
   ],
   "source": [
    "print(beta_test.sum())\n",
    "print(out.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2 3 4\n"
     ]
    }
   ],
   "source": [
    "test_list = range(5)\n",
    "print(*test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n"
     ]
    }
   ],
   "source": [
    "test2 = np.array(15)\n",
    "print(test2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0]\n"
     ]
    }
   ],
   "source": [
    "order0  = np.zeros(test2.shape + (3,), dtype=np.uint32)\n",
    "print(order0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "27581de6d80e5a5a3bac653d6793b7dc8a23f16ccb931cd5e47c2ad8a3cf817b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
