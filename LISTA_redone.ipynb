{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bffb4dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-14 12:30:00.141654: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/saidinesh/.conda/envs/tensorflow-test/lib/python3.9/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf\n",
    "np.random.seed(1)\n",
    "tf.set_random_seed(1)\n",
    "from tools import problems,networks,train\n",
    "import math\n",
    "import sys\n",
    "import numpy.linalg as la\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' # BE QUIET!!!! (info and warnings are not printed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cebfc2f",
   "metadata": {},
   "source": [
    "### M, N, L, pnz, SNR, kappa = 250, 500, 1000, 0.1, 40, 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562ba353",
   "metadata": {},
   "source": [
    "# Bernoulli Gaussian Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb6ecb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19421eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an np matrix A and also a tf tensor (make it constant, since it need not be trained)\n",
    "A = np.random.normal(size=(M, N), scale=1.0 / math.sqrt(M)).astype(np.float32)\n",
    "A_ = tf.constant(A,namea='A')  #Made a tf constant since it need not be trained"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0375d841",
   "metadata": {},
   "source": [
    "Tf variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29271b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate sparse x values drawn from gaussian iid, and non zero locations selected uniformly(with sparsity 0.1).\n",
    "bernoulli_ = tf.cast(tf.random.uniform((N, L))<pnz, tf.float32) \n",
    "xgen_ = bernoulli_ * tf.random.normal((N,L)) \n",
    "\n",
    "noise_var = pnz* N/M * math.pow(10., -SNR/10.)\n",
    "ygen_ = tf.matmul(A_,xgen_) + tf.random.normal( (M,L),stddev=math.sqrt( noise_var ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed801a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"A:0\", shape=(250, 500), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(A_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ba6a17",
   "metadata": {},
   "source": [
    "Np variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b14a5c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "xval = ((np.random.uniform( 0,1,(N,L))<pnz) * np.random.normal(0,1,(N,L))).astype(np.float32)\n",
    "yval = np.matmul(A,xval) + np.random.normal(0,math.sqrt( noise_var ),(M,L))\n",
    "\n",
    "xinit = ((np.random.uniform( 0,1,(N,L))<pnz) * np.random.normal(0,1,(N,L))).astype(np.float32)\n",
    "yinit = np.matmul(A,xinit) + np.random.normal(0,math.sqrt( noise_var ),(M,L))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce2599a",
   "metadata": {},
   "source": [
    "We have created 1000 instances of x and the correspoinding y's using the measurement matrix. Now that we have 1000 (x,y), we use this to train the unfolded neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9292f5f",
   "metadata": {},
   "source": [
    "# Build LISTA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0372c586",
   "metadata": {},
   "outputs": [],
   "source": [
    "T, initial_lambda = 6, 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc56683",
   "metadata": {},
   "source": [
    "Shrinkage function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82ca3646",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_soft_threshold(r_, lam_):\n",
    "    \"implement a soft threshold function y=sign(r)*max(0,abs(r)-lam)\"\n",
    "    lam_ = tf.maximum(lam_, 0)\n",
    "    return tf.sign(r_) * tf.maximum(tf.abs(r_) - lam_, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6bc646f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating placeholders, which will hold dataset later.\n",
    "x_ = tf.compat.v1.placeholder( tf.float32,(N,None),name='x' )\n",
    "y_ = tf.compat.v1.placeholder( tf.float32,(M,None),name='y' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1059901f",
   "metadata": {},
   "outputs": [],
   "source": [
    "eta = simple_soft_threshold #creating an object\n",
    "B = A.T / (1.01 * la.norm(A,2)**2) #(This is according to original code, not sure why)\n",
    "#B = A.T #numpy array\n",
    "\n",
    "# All of these below are tf, which means they will be stored as graphs and will run later. \n",
    "# B and S are the trainable parameters\n",
    "B_ = tf.Variable(B,dtype=tf.float32,name='B_0') #creating tf.variable to make it a trainable parameter. \n",
    "S_ = tf.Variable(np.identity(N) - np.matmul(B, A),dtype=tf.float32,name='S_0' )\n",
    "\n",
    "By_ = tf.matmul(B_,y_)  # This will be the input for the shrinkage function in the first iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b1d986b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'B_0:0' shape=(500, 250) dtype=float32_ref>\n",
      "Tensor(\"MatMul_1:0\", shape=(500, ?), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(B_)\n",
    "print(By_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d138ac01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# not sure why it is written as a list. Might get clear later.\n",
    "layers = []\n",
    "layers.append( ('Linear',By_,None) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0acc687d",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_lambda = np.array(initial_lambda).astype(np.float32)\n",
    "lam0_ = tf.Variable(initial_lambda,name='lam_0')  #to make it learnable\n",
    "\n",
    "xhat_ = eta( By_, lam0_) #first itertion and xhat_0 is all 0s\n",
    "layers.append( ('LISTA T=1',xhat_, (lam0_,) ) )\n",
    "\n",
    "for t in range(1,T):\n",
    "    lam_ = tf.Variable( initial_lambda,name='lam_{0}'.format(t) ) # using the same lambda\n",
    "    xhat_ = eta( tf.matmul(S_,xhat_) + By_, lam_ )  # will be stored as graphs which will run during a session later.   \n",
    "    layers.append( ('LISTA T='+str(t+1),xhat_,(lam_,)) ) # creating layers (xhat_ is an operation)         \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3050a4cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Linear', <tf.Tensor 'MatMul_1:0' shape=(500, ?) dtype=float32>, None)\n",
      "('LISTA T=1', <tf.Tensor 'mul_1:0' shape=(500, ?) dtype=float32>, (<tf.Variable 'lam_0:0' shape=() dtype=float32_ref>,))\n",
      "('LISTA T=2', <tf.Tensor 'mul_2:0' shape=(500, ?) dtype=float32>, (<tf.Variable 'lam_1:0' shape=() dtype=float32_ref>,))\n",
      "('LISTA T=3', <tf.Tensor 'mul_3:0' shape=(500, ?) dtype=float32>, (<tf.Variable 'lam_2:0' shape=() dtype=float32_ref>,))\n",
      "('LISTA T=4', <tf.Tensor 'mul_4:0' shape=(500, ?) dtype=float32>, (<tf.Variable 'lam_3:0' shape=() dtype=float32_ref>,))\n",
      "('LISTA T=5', <tf.Tensor 'mul_5:0' shape=(500, ?) dtype=float32>, (<tf.Variable 'lam_4:0' shape=() dtype=float32_ref>,))\n",
      "('LISTA T=6', <tf.Tensor 'mul_6:0' shape=(500, ?) dtype=float32>, (<tf.Variable 'lam_5:0' shape=() dtype=float32_ref>,))\n",
      "<tf.Variable 'lam_0:0' shape=() dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "print(*layers , sep = \"\\n\")\n",
    "print(lam0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d779407e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"MatMul_1:0\", shape=(500, ?), dtype=float32)\n",
      "Tensor(\"mul_1:0\", shape=(500, ?), dtype=float32)\n",
      "Tensor(\"mul_2:0\", shape=(500, ?), dtype=float32)\n",
      "Tensor(\"mul_3:0\", shape=(500, ?), dtype=float32)\n",
      "Tensor(\"mul_4:0\", shape=(500, ?), dtype=float32)\n",
      "Tensor(\"mul_5:0\", shape=(500, ?), dtype=float32)\n",
      "Tensor(\"mul_6:0\", shape=(500, ?), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for name,xhat_,var_list in layers:\n",
    "    print(xhat_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb46182",
   "metadata": {},
   "source": [
    "# Setup training LISTA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9b6c6283",
   "metadata": {},
   "outputs": [],
   "source": [
    "trinit,refinements,final_refine = 1e-3, (.5,.1,.01), None\n",
    "losses_=[]\n",
    "nmse_=[]\n",
    "trainers_=[]\n",
    "\n",
    "\"\"\"assert is used when, If the statement is true then it does nothing and continues \n",
    "the execution, but if the statement is False then it stops the execution of the program \n",
    "and throws an error.\n",
    "\"\"\"\n",
    "assert np.array(refinements).min()>0,'all refinements must be in (0,1]'\n",
    "assert np.array(refinements).max()<=1,'all refinements must be in (0,1]'\n",
    "\n",
    "tr_ = tf.Variable(trinit,name='tr',trainable=False) #Learning rate\n",
    "training_stages=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7b8c6723",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.disable_v2_behavior() #compatibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b31b2865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # creating placeholders, which will hold dataset later.\n",
    "# x_ = tf.compat.v1.placeholder( tf.float32,(N,None),name='x' )\n",
    "# y_ = tf.compat.v1.placeholder( tf.float32,(M,None),name='y' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3a087cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"x:0\", shape=(500, ?), dtype=float32)\n",
      "Tensor(\"y:0\", shape=(250, ?), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(x_)\n",
    "print(y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eb92c9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nmse_denom_ = tf.nn.l2_loss(x_)  #computes half of l2 loss without the sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f33d24ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name,xhat_,var_list in layers:\n",
    "    loss_  = tf.nn.l2_loss( xhat_ - x_) #original values of x will be stored in the placeholder\n",
    "    nmse_  = tf.nn.l2_loss( (xhat_ - x_) ) / nmse_denom_ # computing the nmse.\n",
    "    if var_list is not None:\n",
    "            train_ = tf.train.AdamOptimizer(tr_).minimize(loss_, var_list=var_list) \n",
    "            training_stages.append( (name,xhat_,loss_,nmse_,train_,var_list) )\n",
    "    for fm in refinements:\n",
    "            train2_ = tf.train.AdamOptimizer(tr_*fm).minimize(loss_)\n",
    "            training_stages.append( (name+' trainrate=' + str(fm) ,xhat_,loss_,nmse_,train2_,()) )\n",
    "            \n",
    "if final_refine:\n",
    "    train2_ = tf.train.AdamOptimizer(tr_*final_refine).minimize(loss_)\n",
    "    training_stages.append( (name+' final refine ' + str(final_refine) ,xhat_,loss_,nmse_,train2_,()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ddcd3646",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Linear trainrate=0.5', <tf.Tensor 'MatMul_1:0' shape=(500, ?) dtype=float32>, <tf.Tensor 'L2Loss_1:0' shape=() dtype=float32>, <tf.Tensor 'truediv:0' shape=() dtype=float32>, <tf.Operation 'Adam' type=NoOp>, ())\n",
      "('Linear trainrate=0.1', <tf.Tensor 'MatMul_1:0' shape=(500, ?) dtype=float32>, <tf.Tensor 'L2Loss_1:0' shape=() dtype=float32>, <tf.Tensor 'truediv:0' shape=() dtype=float32>, <tf.Operation 'Adam_1' type=NoOp>, ())\n",
      "('Linear trainrate=0.01', <tf.Tensor 'MatMul_1:0' shape=(500, ?) dtype=float32>, <tf.Tensor 'L2Loss_1:0' shape=() dtype=float32>, <tf.Tensor 'truediv:0' shape=() dtype=float32>, <tf.Operation 'Adam_2' type=NoOp>, ())\n",
      "('LISTA T=1', <tf.Tensor 'mul_1:0' shape=(500, ?) dtype=float32>, <tf.Tensor 'L2Loss_3:0' shape=() dtype=float32>, <tf.Tensor 'truediv_1:0' shape=() dtype=float32>, <tf.Operation 'Adam_3' type=NoOp>, (<tf.Variable 'lam_0:0' shape=() dtype=float32_ref>,))\n",
      "('LISTA T=1 trainrate=0.5', <tf.Tensor 'mul_1:0' shape=(500, ?) dtype=float32>, <tf.Tensor 'L2Loss_3:0' shape=() dtype=float32>, <tf.Tensor 'truediv_1:0' shape=() dtype=float32>, <tf.Operation 'Adam_4' type=NoOp>, ())\n",
      "('LISTA T=1 trainrate=0.1', <tf.Tensor 'mul_1:0' shape=(500, ?) dtype=float32>, <tf.Tensor 'L2Loss_3:0' shape=() dtype=float32>, <tf.Tensor 'truediv_1:0' shape=() dtype=float32>, <tf.Operation 'Adam_5' type=NoOp>, ())\n",
      "('LISTA T=1 trainrate=0.01', <tf.Tensor 'mul_1:0' shape=(500, ?) dtype=float32>, <tf.Tensor 'L2Loss_3:0' shape=() dtype=float32>, <tf.Tensor 'truediv_1:0' shape=() dtype=float32>, <tf.Operation 'Adam_6' type=NoOp>, ())\n",
      "('LISTA T=2', <tf.Tensor 'mul_2:0' shape=(500, ?) dtype=float32>, <tf.Tensor 'L2Loss_5:0' shape=() dtype=float32>, <tf.Tensor 'truediv_2:0' shape=() dtype=float32>, <tf.Operation 'Adam_7' type=NoOp>, (<tf.Variable 'lam_1:0' shape=() dtype=float32_ref>,))\n",
      "('LISTA T=2 trainrate=0.5', <tf.Tensor 'mul_2:0' shape=(500, ?) dtype=float32>, <tf.Tensor 'L2Loss_5:0' shape=() dtype=float32>, <tf.Tensor 'truediv_2:0' shape=() dtype=float32>, <tf.Operation 'Adam_8' type=NoOp>, ())\n",
      "('LISTA T=2 trainrate=0.1', <tf.Tensor 'mul_2:0' shape=(500, ?) dtype=float32>, <tf.Tensor 'L2Loss_5:0' shape=() dtype=float32>, <tf.Tensor 'truediv_2:0' shape=() dtype=float32>, <tf.Operation 'Adam_9' type=NoOp>, ())\n",
      "('LISTA T=2 trainrate=0.01', <tf.Tensor 'mul_2:0' shape=(500, ?) dtype=float32>, <tf.Tensor 'L2Loss_5:0' shape=() dtype=float32>, <tf.Tensor 'truediv_2:0' shape=() dtype=float32>, <tf.Operation 'Adam_10' type=NoOp>, ())\n",
      "('LISTA T=3', <tf.Tensor 'mul_3:0' shape=(500, ?) dtype=float32>, <tf.Tensor 'L2Loss_7:0' shape=() dtype=float32>, <tf.Tensor 'truediv_3:0' shape=() dtype=float32>, <tf.Operation 'Adam_11' type=NoOp>, (<tf.Variable 'lam_2:0' shape=() dtype=float32_ref>,))\n",
      "('LISTA T=3 trainrate=0.5', <tf.Tensor 'mul_3:0' shape=(500, ?) dtype=float32>, <tf.Tensor 'L2Loss_7:0' shape=() dtype=float32>, <tf.Tensor 'truediv_3:0' shape=() dtype=float32>, <tf.Operation 'Adam_12' type=NoOp>, ())\n",
      "('LISTA T=3 trainrate=0.1', <tf.Tensor 'mul_3:0' shape=(500, ?) dtype=float32>, <tf.Tensor 'L2Loss_7:0' shape=() dtype=float32>, <tf.Tensor 'truediv_3:0' shape=() dtype=float32>, <tf.Operation 'Adam_13' type=NoOp>, ())\n",
      "('LISTA T=3 trainrate=0.01', <tf.Tensor 'mul_3:0' shape=(500, ?) dtype=float32>, <tf.Tensor 'L2Loss_7:0' shape=() dtype=float32>, <tf.Tensor 'truediv_3:0' shape=() dtype=float32>, <tf.Operation 'Adam_14' type=NoOp>, ())\n",
      "('LISTA T=4', <tf.Tensor 'mul_4:0' shape=(500, ?) dtype=float32>, <tf.Tensor 'L2Loss_9:0' shape=() dtype=float32>, <tf.Tensor 'truediv_4:0' shape=() dtype=float32>, <tf.Operation 'Adam_15' type=NoOp>, (<tf.Variable 'lam_3:0' shape=() dtype=float32_ref>,))\n",
      "('LISTA T=4 trainrate=0.5', <tf.Tensor 'mul_4:0' shape=(500, ?) dtype=float32>, <tf.Tensor 'L2Loss_9:0' shape=() dtype=float32>, <tf.Tensor 'truediv_4:0' shape=() dtype=float32>, <tf.Operation 'Adam_16' type=NoOp>, ())\n",
      "('LISTA T=4 trainrate=0.1', <tf.Tensor 'mul_4:0' shape=(500, ?) dtype=float32>, <tf.Tensor 'L2Loss_9:0' shape=() dtype=float32>, <tf.Tensor 'truediv_4:0' shape=() dtype=float32>, <tf.Operation 'Adam_17' type=NoOp>, ())\n",
      "('LISTA T=4 trainrate=0.01', <tf.Tensor 'mul_4:0' shape=(500, ?) dtype=float32>, <tf.Tensor 'L2Loss_9:0' shape=() dtype=float32>, <tf.Tensor 'truediv_4:0' shape=() dtype=float32>, <tf.Operation 'Adam_18' type=NoOp>, ())\n",
      "('LISTA T=5', <tf.Tensor 'mul_5:0' shape=(500, ?) dtype=float32>, <tf.Tensor 'L2Loss_11:0' shape=() dtype=float32>, <tf.Tensor 'truediv_5:0' shape=() dtype=float32>, <tf.Operation 'Adam_19' type=NoOp>, (<tf.Variable 'lam_4:0' shape=() dtype=float32_ref>,))\n",
      "('LISTA T=5 trainrate=0.5', <tf.Tensor 'mul_5:0' shape=(500, ?) dtype=float32>, <tf.Tensor 'L2Loss_11:0' shape=() dtype=float32>, <tf.Tensor 'truediv_5:0' shape=() dtype=float32>, <tf.Operation 'Adam_20' type=NoOp>, ())\n",
      "('LISTA T=5 trainrate=0.1', <tf.Tensor 'mul_5:0' shape=(500, ?) dtype=float32>, <tf.Tensor 'L2Loss_11:0' shape=() dtype=float32>, <tf.Tensor 'truediv_5:0' shape=() dtype=float32>, <tf.Operation 'Adam_21' type=NoOp>, ())\n",
      "('LISTA T=5 trainrate=0.01', <tf.Tensor 'mul_5:0' shape=(500, ?) dtype=float32>, <tf.Tensor 'L2Loss_11:0' shape=() dtype=float32>, <tf.Tensor 'truediv_5:0' shape=() dtype=float32>, <tf.Operation 'Adam_22' type=NoOp>, ())\n",
      "('LISTA T=6', <tf.Tensor 'mul_6:0' shape=(500, ?) dtype=float32>, <tf.Tensor 'L2Loss_13:0' shape=() dtype=float32>, <tf.Tensor 'truediv_6:0' shape=() dtype=float32>, <tf.Operation 'Adam_23' type=NoOp>, (<tf.Variable 'lam_5:0' shape=() dtype=float32_ref>,))\n",
      "('LISTA T=6 trainrate=0.5', <tf.Tensor 'mul_6:0' shape=(500, ?) dtype=float32>, <tf.Tensor 'L2Loss_13:0' shape=() dtype=float32>, <tf.Tensor 'truediv_6:0' shape=() dtype=float32>, <tf.Operation 'Adam_24' type=NoOp>, ())\n",
      "('LISTA T=6 trainrate=0.1', <tf.Tensor 'mul_6:0' shape=(500, ?) dtype=float32>, <tf.Tensor 'L2Loss_13:0' shape=() dtype=float32>, <tf.Tensor 'truediv_6:0' shape=() dtype=float32>, <tf.Operation 'Adam_25' type=NoOp>, ())\n",
      "('LISTA T=6 trainrate=0.01', <tf.Tensor 'mul_6:0' shape=(500, ?) dtype=float32>, <tf.Tensor 'L2Loss_13:0' shape=() dtype=float32>, <tf.Tensor 'truediv_6:0' shape=() dtype=float32>, <tf.Operation 'Adam_26' type=NoOp>, ())\n"
     ]
    }
   ],
   "source": [
    "print(*training_stages , sep = \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88119388",
   "metadata": {},
   "source": [
    "# Do Training LISTA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1511f6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_trainable_vars(sess,filename,**kwargs):\n",
    "    \"\"\"save a .npz archive in `filename`  with\n",
    "    the current value of each variable in tf.trainable_variables()\n",
    "    plus any keyword numpy arrays.\n",
    "    \"\"\"\n",
    "    save={}\n",
    "    for v in tf.trainable_variables():\n",
    "        save[str(v.name)] = sess.run(v)\n",
    "    save.update(kwargs)\n",
    "    np.savez(filename,**save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6f71e064",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_trainable_vars(sess,filename):\n",
    "    \"\"\"load a .npz archive and assign the value of each loaded\n",
    "    ndarray to the trainable variable whose name matches the\n",
    "    archive key.  Any elements in the archive that do not have\n",
    "    a corresponding trainable variable will be returned in a dict.\n",
    "    \"\"\"\n",
    "    other={}\n",
    "    try:\n",
    "        tv=dict([ (str(v.name),v) for v in tf.trainable_variables() ])\n",
    "        for k,d in np.load(filename).items():\n",
    "            if k in tv:\n",
    "                print('restoring ' + k)\n",
    "                sess.run(tf.assign( tv[k], d) )\n",
    "            else:\n",
    "                other[k] = d\n",
    "    except IOError:\n",
    "        pass\n",
    "    return other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "00743e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-27 18:54:09.391416: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-06-27 18:54:09.392550: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2022-06-27 18:54:09.450037: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:17:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5\n",
      "coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s\n",
      "2022-06-27 18:54:09.450701: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: \n",
      "pciBusID: 0000:65:00.0 name: Quadro P2200 computeCapability: 6.1\n",
      "coreClock: 1.493GHz coreCount: 10 deviceMemorySize: 4.94GiB deviceMemoryBandwidth: 186.45GiB/s\n",
      "2022-06-27 18:54:09.450727: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-06-27 18:54:09.452473: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-06-27 18:54:09.452542: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-06-27 18:54:09.454299: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-06-27 18:54:09.454628: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-06-27 18:54:09.456387: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-06-27 18:54:09.457380: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-06-27 18:54:09.461137: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-06-27 18:54:09.462924: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1\n",
      "2022-06-27 18:54:09.463640: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-27 18:54:09.466919: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-06-27 18:54:09.639553: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:17:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5\n",
      "coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s\n",
      "2022-06-27 18:54:09.640091: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: \n",
      "pciBusID: 0000:65:00.0 name: Quadro P2200 computeCapability: 6.1\n",
      "coreClock: 1.493GHz coreCount: 10 deviceMemorySize: 4.94GiB deviceMemoryBandwidth: 186.45GiB/s\n",
      "2022-06-27 18:54:09.640134: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-06-27 18:54:09.640158: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-06-27 18:54:09.640172: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-06-27 18:54:09.640186: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-06-27 18:54:09.640200: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-06-27 18:54:09.640214: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-06-27 18:54:09.640227: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-06-27 18:54:09.640242: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-06-27 18:54:09.643423: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1\n",
      "2022-06-27 18:54:09.643523: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-06-27 18:54:10.247271: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-06-27 18:54:10.247308: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 1 \n",
      "2022-06-27 18:54:10.247312: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N N \n",
      "2022-06-27 18:54:10.247314: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 1:   N N \n",
      "2022-06-27 18:54:10.248735: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10070 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:17:00.0, compute capability: 7.5)\n",
      "2022-06-27 18:54:10.249594: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 4521 MB memory) -> physical GPU (device: 1, name: Quadro P2200, pci bus id: 0000:65:00.0, compute capability: 6.1)\n",
      "2022-06-27 18:54:10.292669: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:196] None of the MLIR optimization passes are enabled (registered 0 passes)\n",
      "2022-06-27 18:54:10.356959: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3000000000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norms xval:224.5516663 yval:224.0477230\n",
      "Linear trainrate=0.5 fine tuning all B_0:0,S_0:0,lam_0:0,lam_1:0,lam_2:0,lam_3:0,lam_4:0,lam_5:0\n",
      "i=0      nmse=-1.295706 dB (best=-1.295706)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-27 18:54:10.605730: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "i=1000   nmse=-2.976344 dB (best=-2.978776)\n",
      "i=2000   nmse=-2.978988 dB (best=-2.980044)\n",
      "i=3000   nmse=-2.976944 dB (best=-2.980044)\n",
      "i=4000   nmse=-2.976935 dB (best=-2.980044)\n",
      "i=5000   nmse=-2.976858 dB (best=-2.980564)\n",
      "i=6000   nmse=-2.976022 dB (best=-2.980564)\n",
      "i=7000   nmse=-2.979383 dB (best=-2.980831)\n",
      "i=8000   nmse=-2.977289 dB (best=-2.980831)\n",
      "i=9000   nmse=-2.978209 dB (best=-2.980831)\n",
      "i=10000  nmse=-2.978140 dB (best=-2.980831)\n",
      "i=11000  nmse=-2.977339 dB (best=-2.980831)\n",
      "i=12000  nmse=-2.976546 dB (best=-2.980831)\n",
      "Linear trainrate=0.1 fine tuning all B_0:0,S_0:0,lam_0:0,lam_1:0,lam_2:0,lam_3:0,lam_4:0,lam_5:0\n",
      "i=0      nmse=-2.976546 dB (best=-2.976546)\n",
      "i=1000   nmse=-2.990776 dB (best=-2.991474)\n",
      "i=2000   nmse=-2.990935 dB (best=-2.991608)\n",
      "i=3000   nmse=-2.991336 dB (best=-2.992029)\n",
      "i=4000   nmse=-2.990816 dB (best=-2.992029)\n",
      "i=5000   nmse=-2.991111 dB (best=-2.992136)\n",
      "i=6000   nmse=-2.990504 dB (best=-2.992136)\n",
      "i=7000   nmse=-2.990688 dB (best=-2.992136)\n",
      "i=8000   nmse=-2.991970 dB (best=-2.992275)\n",
      "i=9000   nmse=-2.990561 dB (best=-2.992275)\n",
      "i=10000  nmse=-2.991242 dB (best=-2.992275)\n",
      "i=11000  nmse=-2.991317 dB (best=-2.992275)\n",
      "i=12000  nmse=-2.990927 dB (best=-2.992806)\n",
      "i=13000  nmse=-2.990558 dB (best=-2.992806)\n",
      "i=14000  nmse=-2.990412 dB (best=-2.992806)\n",
      "i=15000  nmse=-2.991534 dB (best=-2.992806)\n",
      "i=16000  nmse=-2.990519 dB (best=-2.992806)\n",
      "i=17000  nmse=-2.990534 dB (best=-2.992806)\n",
      "Linear trainrate=0.01 fine tuning all B_0:0,S_0:0,lam_0:0,lam_1:0,lam_2:0,lam_3:0,lam_4:0,lam_5:0\n",
      "i=0      nmse=-2.990534 dB (best=-2.990533)\n",
      "i=1000   nmse=-2.992953 dB (best=-2.992953)\n",
      "i=2000   nmse=-2.993275 dB (best=-2.993331)\n",
      "i=3000   nmse=-2.993611 dB (best=-2.993658)\n",
      "i=4000   nmse=-2.993532 dB (best=-2.993767)\n",
      "i=5000   nmse=-2.993896 dB (best=-2.993913)\n",
      "i=6000   nmse=-2.994091 dB (best=-2.994118)\n",
      "i=7000   nmse=-2.993990 dB (best=-2.994119)\n",
      "i=8000   nmse=-2.993866 dB (best=-2.994119)\n",
      "i=9000   nmse=-2.993985 dB (best=-2.994119)\n",
      "i=10000  nmse=-2.993973 dB (best=-2.994119)\n",
      "i=11000  nmse=-2.994094 dB (best=-2.994173)\n",
      "i=12000  nmse=-2.994153 dB (best=-2.994337)\n",
      "i=13000  nmse=-2.994221 dB (best=-2.994337)\n",
      "i=14000  nmse=-2.993955 dB (best=-2.994337)\n",
      "i=15000  nmse=-2.994197 dB (best=-2.994337)\n",
      "i=16000  nmse=-2.994082 dB (best=-2.994337)\n",
      "i=17000  nmse=-2.994210 dB (best=-2.994368)\n",
      "i=18000  nmse=-2.994267 dB (best=-2.994368)\n",
      "i=19000  nmse=-2.994120 dB (best=-2.994368)\n",
      "i=20000  nmse=-2.994206 dB (best=-2.994368)\n",
      "i=21000  nmse=-2.994178 dB (best=-2.994413)\n",
      "i=22000  nmse=-2.993995 dB (best=-2.994413)\n",
      "i=23000  nmse=-2.994177 dB (best=-2.994413)\n",
      "i=24000  nmse=-2.994331 dB (best=-2.994413)\n",
      "i=25000  nmse=-2.993968 dB (best=-2.994413)\n",
      "i=26000  nmse=-2.994223 dB (best=-2.994413)\n",
      "LISTA T=1 extending lam_0:0\n",
      "i=0      nmse=-3.678127 dB (best=-3.678126)\n",
      "i=1000   nmse=-3.679895 dB (best=-3.679903)\n",
      "i=2000   nmse=-3.679897 dB (best=-3.679903)\n",
      "i=3000   nmse=-3.679869 dB (best=-3.679903)\n",
      "i=4000   nmse=-3.679903 dB (best=-3.679904)\n",
      "i=5000   nmse=-3.679903 dB (best=-3.679904)\n",
      "i=6000   nmse=-3.679891 dB (best=-3.679904)\n",
      "i=7000   nmse=-3.679903 dB (best=-3.679904)\n",
      "i=8000   nmse=-3.679863 dB (best=-3.679904)\n",
      "i=9000   nmse=-3.679891 dB (best=-3.679904)\n",
      "LISTA T=1 trainrate=0.5 fine tuning all B_0:0,S_0:0,lam_0:0,lam_1:0,lam_2:0,lam_3:0,lam_4:0,lam_5:0\n",
      "i=0      nmse=-3.679891 dB (best=-3.679891)\n",
      "i=1000   nmse=-6.143201 dB (best=-6.143201)\n",
      "i=2000   nmse=-6.357973 dB (best=-6.358150)\n",
      "i=3000   nmse=-6.385462 dB (best=-6.385461)\n",
      "i=4000   nmse=-6.387103 dB (best=-6.395317)\n",
      "i=5000   nmse=-6.388932 dB (best=-6.395317)\n",
      "i=6000   nmse=-6.389239 dB (best=-6.395317)\n",
      "i=7000   nmse=-6.386518 dB (best=-6.395338)\n",
      "i=8000   nmse=-6.390795 dB (best=-6.395338)\n",
      "i=9000   nmse=-6.389599 dB (best=-6.395338)\n",
      "i=10000  nmse=-6.392037 dB (best=-6.395338)\n",
      "i=11000  nmse=-6.389722 dB (best=-6.395338)\n",
      "i=12000  nmse=-6.388614 dB (best=-6.396017)\n",
      "i=13000  nmse=-6.384325 dB (best=-6.396017)\n",
      "i=14000  nmse=-6.388518 dB (best=-6.396017)\n",
      "i=15000  nmse=-6.386290 dB (best=-6.396017)\n",
      "i=16000  nmse=-6.387893 dB (best=-6.396017)\n",
      "i=17000  nmse=-6.390000 dB (best=-6.396017)\n",
      "LISTA T=1 trainrate=0.1 fine tuning all B_0:0,S_0:0,lam_0:0,lam_1:0,lam_2:0,lam_3:0,lam_4:0,lam_5:0\n",
      "i=0      nmse=-6.390000 dB (best=-6.390000)\n",
      "i=1000   nmse=-6.406523 dB (best=-6.406523)\n",
      "i=2000   nmse=-6.407529 dB (best=-6.408918)\n",
      "i=3000   nmse=-6.408218 dB (best=-6.409401)\n",
      "i=4000   nmse=-6.406422 dB (best=-6.409401)\n",
      "i=5000   nmse=-6.406893 dB (best=-6.409401)\n",
      "i=6000   nmse=-6.405106 dB (best=-6.409401)\n",
      "i=7000   nmse=-6.407664 dB (best=-6.409401)\n",
      "i=8000   nmse=-6.407136 dB (best=-6.409401)\n",
      "LISTA T=1 trainrate=0.01 fine tuning all B_0:0,S_0:0,lam_0:0,lam_1:0,lam_2:0,lam_3:0,lam_4:0,lam_5:0\n",
      "i=0      nmse=-6.407136 dB (best=-6.407136)\n",
      "i=1000   nmse=-6.408239 dB (best=-6.408239)\n",
      "i=2000   nmse=-6.409036 dB (best=-6.409036)\n",
      "i=3000   nmse=-6.409653 dB (best=-6.409709)\n",
      "i=4000   nmse=-6.410067 dB (best=-6.410067)\n",
      "i=5000   nmse=-6.410098 dB (best=-6.410208)\n",
      "i=6000   nmse=-6.410442 dB (best=-6.410459)\n",
      "i=7000   nmse=-6.410686 dB (best=-6.410687)\n",
      "i=8000   nmse=-6.410809 dB (best=-6.410815)\n",
      "i=9000   nmse=-6.410705 dB (best=-6.410815)\n",
      "i=10000  nmse=-6.410629 dB (best=-6.410947)\n",
      "i=11000  nmse=-6.410757 dB (best=-6.410947)\n",
      "i=12000  nmse=-6.410536 dB (best=-6.410947)\n",
      "i=13000  nmse=-6.410573 dB (best=-6.410947)\n",
      "i=14000  nmse=-6.410380 dB (best=-6.410947)\n",
      "i=15000  nmse=-6.410462 dB (best=-6.410947)\n",
      "LISTA T=2 extending lam_1:0\n",
      "i=0      nmse=2.816069 dB (best=2.816069)\n",
      "i=1000   nmse=-2.281205 dB (best=-2.281205)\n",
      "i=2000   nmse=-3.764718 dB (best=-3.764717)\n",
      "i=3000   nmse=-4.175770 dB (best=-4.175770)\n",
      "i=4000   nmse=-4.250669 dB (best=-4.250669)\n",
      "i=5000   nmse=-4.254740 dB (best=-4.254933)\n",
      "i=6000   nmse=-4.254158 dB (best=-4.254933)\n",
      "i=7000   nmse=-4.254172 dB (best=-4.254933)\n",
      "i=8000   nmse=-4.254142 dB (best=-4.254933)\n",
      "i=9000   nmse=-4.254018 dB (best=-4.254933)\n",
      "i=10000  nmse=-4.253991 dB (best=-4.254933)\n",
      "LISTA T=2 trainrate=0.5 fine tuning all B_0:0,S_0:0,lam_0:0,lam_1:0,lam_2:0,lam_3:0,lam_4:0,lam_5:0\n",
      "i=0      nmse=-4.253991 dB (best=-4.253991)\n",
      "i=1000   nmse=-6.833111 dB (best=-6.833111)\n",
      "i=2000   nmse=-9.559151 dB (best=-9.559151)\n",
      "i=3000   nmse=-11.001661 dB (best=-11.001661)\n",
      "i=4000   nmse=-11.150210 dB (best=-11.151753)\n",
      "i=5000   nmse=-11.237527 dB (best=-11.237526)\n",
      "i=6000   nmse=-11.307188 dB (best=-11.307613)\n",
      "i=7000   nmse=-11.336782 dB (best=-11.343923)\n",
      "i=8000   nmse=-11.364534 dB (best=-11.371886)\n",
      "i=9000   nmse=-11.377310 dB (best=-11.379654)\n",
      "i=10000  nmse=-11.380963 dB (best=-11.392284)\n",
      "i=11000  nmse=-11.388507 dB (best=-11.398439)\n",
      "i=12000  nmse=-11.384443 dB (best=-11.398769)\n",
      "i=13000  nmse=-11.384618 dB (best=-11.403461)\n",
      "i=14000  nmse=-11.392820 dB (best=-11.403461)\n",
      "i=15000  nmse=-11.385425 dB (best=-11.403512)\n",
      "i=16000  nmse=-11.404089 dB (best=-11.405952)\n",
      "i=17000  nmse=-11.390133 dB (best=-11.410442)\n",
      "i=18000  nmse=-11.392035 dB (best=-11.410442)\n",
      "i=19000  nmse=-11.402177 dB (best=-11.410442)\n",
      "i=20000  nmse=-11.391708 dB (best=-11.410442)\n",
      "i=21000  nmse=-11.387297 dB (best=-11.410442)\n",
      "i=22000  nmse=-11.395299 dB (best=-11.410442)\n",
      "LISTA T=2 trainrate=0.1 fine tuning all B_0:0,S_0:0,lam_0:0,lam_1:0,lam_2:0,lam_3:0,lam_4:0,lam_5:0\n",
      "i=0      nmse=-11.395299 dB (best=-11.395299)\n",
      "i=1000   nmse=-11.487067 dB (best=-11.489066)\n",
      "i=2000   nmse=-11.487840 dB (best=-11.492665)\n",
      "i=3000   nmse=-11.489159 dB (best=-11.493377)\n",
      "i=4000   nmse=-11.487164 dB (best=-11.493377)\n",
      "i=5000   nmse=-11.484892 dB (best=-11.493377)\n",
      "i=6000   nmse=-11.488644 dB (best=-11.493377)\n",
      "i=7000   nmse=-11.483892 dB (best=-11.493377)\n",
      "i=8000   nmse=-11.486703 dB (best=-11.493377)\n",
      "LISTA T=2 trainrate=0.01 fine tuning all B_0:0,S_0:0,lam_0:0,lam_1:0,lam_2:0,lam_3:0,lam_4:0,lam_5:0\n",
      "i=0      nmse=-11.486703 dB (best=-11.486703)\n",
      "i=1000   nmse=-11.497297 dB (best=-11.497297)\n",
      "i=2000   nmse=-11.503084 dB (best=-11.503083)\n",
      "i=3000   nmse=-11.504406 dB (best=-11.504406)\n",
      "i=4000   nmse=-11.506331 dB (best=-11.506516)\n",
      "i=5000   nmse=-11.506819 dB (best=-11.507686)\n",
      "i=6000   nmse=-11.507461 dB (best=-11.507686)\n",
      "i=7000   nmse=-11.508372 dB (best=-11.508421)\n",
      "i=8000   nmse=-11.507885 dB (best=-11.508453)\n",
      "i=9000   nmse=-11.507835 dB (best=-11.508453)\n",
      "i=10000  nmse=-11.508964 dB (best=-11.508992)\n",
      "i=11000  nmse=-11.509079 dB (best=-11.509927)\n",
      "i=12000  nmse=-11.508532 dB (best=-11.509927)\n",
      "i=13000  nmse=-11.509625 dB (best=-11.509927)\n",
      "i=14000  nmse=-11.509510 dB (best=-11.509927)\n",
      "i=15000  nmse=-11.510037 dB (best=-11.510068)\n",
      "i=16000  nmse=-11.509595 dB (best=-11.510149)\n",
      "i=17000  nmse=-11.509118 dB (best=-11.510149)\n",
      "i=18000  nmse=-11.508303 dB (best=-11.510149)\n",
      "i=19000  nmse=-11.508496 dB (best=-11.510149)\n",
      "i=20000  nmse=-11.508863 dB (best=-11.510149)\n",
      "i=21000  nmse=-11.509287 dB (best=-11.510167)\n",
      "i=22000  nmse=-11.509700 dB (best=-11.510167)\n",
      "i=23000  nmse=-11.509761 dB (best=-11.510167)\n",
      "i=24000  nmse=-11.510690 dB (best=-11.510690)\n",
      "i=25000  nmse=-11.509867 dB (best=-11.511217)\n",
      "i=26000  nmse=-11.510395 dB (best=-11.511217)\n",
      "i=27000  nmse=-11.510156 dB (best=-11.511217)\n",
      "i=28000  nmse=-11.510825 dB (best=-11.511217)\n",
      "i=29000  nmse=-11.510460 dB (best=-11.511217)\n",
      "i=30000  nmse=-11.510936 dB (best=-11.511217)\n",
      "LISTA T=3 extending lam_2:0\n",
      "i=0      nmse=-5.810493 dB (best=-5.810493)\n",
      "i=1000   nmse=-9.809794 dB (best=-9.809794)\n",
      "i=2000   nmse=-9.812232 dB (best=-9.812234)\n",
      "i=3000   nmse=-9.812226 dB (best=-9.812234)\n",
      "i=4000   nmse=-9.812230 dB (best=-9.812235)\n",
      "i=5000   nmse=-9.812231 dB (best=-9.812235)\n",
      "i=6000   nmse=-9.812225 dB (best=-9.812235)\n",
      "i=7000   nmse=-9.812227 dB (best=-9.812235)\n",
      "i=8000   nmse=-9.812222 dB (best=-9.812235)\n",
      "i=9000   nmse=-9.812231 dB (best=-9.812235)\n",
      "LISTA T=3 trainrate=0.5 fine tuning all B_0:0,S_0:0,lam_0:0,lam_1:0,lam_2:0,lam_3:0,lam_4:0,lam_5:0\n",
      "i=0      nmse=-9.812231 dB (best=-9.812231)\n",
      "i=1000   nmse=-14.097277 dB (best=-14.097275)\n",
      "i=2000   nmse=-14.240521 dB (best=-14.243168)\n",
      "i=3000   nmse=-14.340686 dB (best=-14.340685)\n",
      "i=4000   nmse=-14.375867 dB (best=-14.381146)\n",
      "i=5000   nmse=-14.383723 dB (best=-14.398498)\n",
      "i=6000   nmse=-14.384547 dB (best=-14.420053)\n",
      "i=7000   nmse=-14.405273 dB (best=-14.423443)\n",
      "i=8000   nmse=-14.400263 dB (best=-14.423443)\n",
      "i=9000   nmse=-14.383451 dB (best=-14.423443)\n",
      "i=10000  nmse=-14.390082 dB (best=-14.423443)\n",
      "i=11000  nmse=-14.399379 dB (best=-14.430073)\n",
      "i=12000  nmse=-14.386435 dB (best=-14.430073)\n",
      "i=13000  nmse=-14.390996 dB (best=-14.430073)\n",
      "i=14000  nmse=-14.402969 dB (best=-14.430073)\n",
      "i=15000  nmse=-14.399564 dB (best=-14.430073)\n",
      "i=16000  nmse=-14.388428 dB (best=-14.430073)\n",
      "LISTA T=3 trainrate=0.1 fine tuning all B_0:0,S_0:0,lam_0:0,lam_1:0,lam_2:0,lam_3:0,lam_4:0,lam_5:0\n",
      "i=0      nmse=-14.388428 dB (best=-14.388427)\n",
      "i=1000   nmse=-14.599164 dB (best=-14.602686)\n",
      "i=2000   nmse=-14.604133 dB (best=-14.605223)\n",
      "i=3000   nmse=-14.609777 dB (best=-14.610906)\n",
      "i=4000   nmse=-14.610326 dB (best=-14.614816)\n",
      "i=5000   nmse=-14.608468 dB (best=-14.620494)\n",
      "i=6000   nmse=-14.608254 dB (best=-14.620494)\n",
      "i=7000   nmse=-14.617076 dB (best=-14.620494)\n",
      "i=8000   nmse=-14.608384 dB (best=-14.621586)\n",
      "i=9000   nmse=-14.600737 dB (best=-14.621586)\n",
      "i=10000  nmse=-14.608155 dB (best=-14.621586)\n",
      "i=11000  nmse=-14.608597 dB (best=-14.621586)\n",
      "i=12000  nmse=-14.606603 dB (best=-14.621586)\n",
      "i=13000  nmse=-14.613124 dB (best=-14.621586)\n",
      "LISTA T=3 trainrate=0.01 fine tuning all B_0:0,S_0:0,lam_0:0,lam_1:0,lam_2:0,lam_3:0,lam_4:0,lam_5:0\n",
      "i=0      nmse=-14.613124 dB (best=-14.613123)\n",
      "i=1000   nmse=-14.645692 dB (best=-14.645692)\n",
      "i=2000   nmse=-14.653988 dB (best=-14.653987)\n",
      "i=3000   nmse=-14.656383 dB (best=-14.656381)\n",
      "i=4000   nmse=-14.656750 dB (best=-14.657748)\n",
      "i=5000   nmse=-14.657845 dB (best=-14.658858)\n",
      "i=6000   nmse=-14.657669 dB (best=-14.658858)\n",
      "i=7000   nmse=-14.657718 dB (best=-14.659528)\n",
      "i=8000   nmse=-14.660192 dB (best=-14.660191)\n",
      "i=9000   nmse=-14.659159 dB (best=-14.660690)\n",
      "i=10000  nmse=-14.658233 dB (best=-14.660690)\n",
      "i=11000  nmse=-14.658290 dB (best=-14.660690)\n",
      "i=12000  nmse=-14.656850 dB (best=-14.660690)\n",
      "i=13000  nmse=-14.657774 dB (best=-14.660690)\n",
      "i=14000  nmse=-14.657840 dB (best=-14.660690)\n",
      "LISTA T=4 extending lam_3:0\n",
      "i=0      nmse=-12.568276 dB (best=-12.568275)\n",
      "i=1000   nmse=-13.084676 dB (best=-13.084680)\n",
      "i=2000   nmse=-13.084478 dB (best=-13.084701)\n",
      "i=3000   nmse=-13.084655 dB (best=-13.084701)\n",
      "i=4000   nmse=-13.084341 dB (best=-13.084701)\n",
      "i=5000   nmse=-13.084358 dB (best=-13.084701)\n",
      "i=6000   nmse=-13.084692 dB (best=-13.084701)\n",
      "i=7000   nmse=-13.084701 dB (best=-13.084701)\n",
      "i=8000   nmse=-13.084700 dB (best=-13.084701)\n",
      "i=9000   nmse=-13.084698 dB (best=-13.084701)\n",
      "LISTA T=4 trainrate=0.5 fine tuning all B_0:0,S_0:0,lam_0:0,lam_1:0,lam_2:0,lam_3:0,lam_4:0,lam_5:0\n",
      "i=0      nmse=-13.084698 dB (best=-13.084697)\n",
      "i=1000   nmse=-16.966166 dB (best=-17.000274)\n",
      "i=2000   nmse=-16.988392 dB (best=-17.015558)\n",
      "i=3000   nmse=-16.999118 dB (best=-17.040069)\n",
      "i=4000   nmse=-17.002045 dB (best=-17.040069)\n",
      "i=5000   nmse=-17.023549 dB (best=-17.040069)\n",
      "i=6000   nmse=-16.995381 dB (best=-17.040069)\n",
      "i=7000   nmse=-16.983337 dB (best=-17.040069)\n",
      "i=8000   nmse=-17.000467 dB (best=-17.044688)\n",
      "i=9000   nmse=-17.023501 dB (best=-17.044688)\n",
      "i=10000  nmse=-17.027298 dB (best=-17.044688)\n",
      "i=11000  nmse=-16.995012 dB (best=-17.044688)\n",
      "i=12000  nmse=-16.992800 dB (best=-17.044688)\n",
      "i=13000  nmse=-16.979742 dB (best=-17.044688)\n",
      "LISTA T=4 trainrate=0.1 fine tuning all B_0:0,S_0:0,lam_0:0,lam_1:0,lam_2:0,lam_3:0,lam_4:0,lam_5:0\n",
      "i=0      nmse=-16.979742 dB (best=-16.979742)\n",
      "i=1000   nmse=-17.328392 dB (best=-17.342713)\n",
      "i=2000   nmse=-17.348006 dB (best=-17.353859)\n",
      "i=3000   nmse=-17.338238 dB (best=-17.353859)\n",
      "i=4000   nmse=-17.340676 dB (best=-17.353859)\n",
      "i=5000   nmse=-17.349478 dB (best=-17.356169)\n",
      "i=6000   nmse=-17.353039 dB (best=-17.356169)\n",
      "i=7000   nmse=-17.346189 dB (best=-17.357869)\n",
      "i=8000   nmse=-17.333578 dB (best=-17.359240)\n",
      "i=9000   nmse=-17.335262 dB (best=-17.359240)\n",
      "i=10000  nmse=-17.355447 dB (best=-17.359240)\n",
      "i=11000  nmse=-17.354038 dB (best=-17.359724)\n",
      "i=12000  nmse=-17.344513 dB (best=-17.359724)\n",
      "i=13000  nmse=-17.337958 dB (best=-17.361443)\n",
      "i=14000  nmse=-17.351079 dB (best=-17.361443)\n",
      "i=15000  nmse=-17.340531 dB (best=-17.365860)\n",
      "i=16000  nmse=-17.344004 dB (best=-17.365860)\n",
      "i=17000  nmse=-17.336508 dB (best=-17.365860)\n",
      "i=18000  nmse=-17.319157 dB (best=-17.365860)\n",
      "i=19000  nmse=-17.355543 dB (best=-17.365860)\n",
      "i=20000  nmse=-17.339903 dB (best=-17.365860)\n",
      "LISTA T=4 trainrate=0.01 fine tuning all B_0:0,S_0:0,lam_0:0,lam_1:0,lam_2:0,lam_3:0,lam_4:0,lam_5:0\n",
      "i=0      nmse=-17.339903 dB (best=-17.339903)\n",
      "i=1000   nmse=-17.400733 dB (best=-17.400733)\n",
      "i=2000   nmse=-17.412292 dB (best=-17.413024)\n",
      "i=3000   nmse=-17.416641 dB (best=-17.416867)\n",
      "i=4000   nmse=-17.422893 dB (best=-17.423725)\n",
      "i=5000   nmse=-17.423936 dB (best=-17.424544)\n",
      "i=6000   nmse=-17.420806 dB (best=-17.425344)\n",
      "i=7000   nmse=-17.424500 dB (best=-17.425344)\n",
      "i=8000   nmse=-17.425188 dB (best=-17.425973)\n",
      "i=9000   nmse=-17.422743 dB (best=-17.425973)\n",
      "i=10000  nmse=-17.420287 dB (best=-17.425973)\n",
      "i=11000  nmse=-17.419422 dB (best=-17.425973)\n",
      "i=12000  nmse=-17.421730 dB (best=-17.425973)\n",
      "i=13000  nmse=-17.421162 dB (best=-17.425973)\n",
      "LISTA T=5 extending lam_4:0\n",
      "i=0      nmse=-17.476504 dB (best=-17.476503)\n",
      "i=1000   nmse=-17.537857 dB (best=-17.537990)\n",
      "i=2000   nmse=-17.537947 dB (best=-17.537990)\n",
      "i=3000   nmse=-17.537541 dB (best=-17.537990)\n",
      "i=4000   nmse=-17.537971 dB (best=-17.537990)\n",
      "i=5000   nmse=-17.537673 dB (best=-17.537990)\n",
      "i=6000   nmse=-17.537501 dB (best=-17.537990)\n",
      "LISTA T=5 trainrate=0.5 fine tuning all B_0:0,S_0:0,lam_0:0,lam_1:0,lam_2:0,lam_3:0,lam_4:0,lam_5:0\n",
      "i=0      nmse=-17.537501 dB (best=-17.537500)\n",
      "i=1000   nmse=-19.453657 dB (best=-19.512925)\n",
      "i=2000   nmse=-19.500951 dB (best=-19.512925)\n",
      "i=3000   nmse=-19.402295 dB (best=-19.512925)\n",
      "i=4000   nmse=-19.407480 dB (best=-19.512925)\n",
      "i=5000   nmse=-19.495965 dB (best=-19.512925)\n",
      "i=6000   nmse=-19.480244 dB (best=-19.512925)\n",
      "LISTA T=5 trainrate=0.1 fine tuning all B_0:0,S_0:0,lam_0:0,lam_1:0,lam_2:0,lam_3:0,lam_4:0,lam_5:0\n",
      "i=0      nmse=-19.480244 dB (best=-19.480242)\n",
      "i=1000   nmse=-19.987106 dB (best=-20.007388)\n",
      "i=2000   nmse=-19.996644 dB (best=-20.010244)\n",
      "i=3000   nmse=-19.998975 dB (best=-20.020196)\n",
      "i=4000   nmse=-19.994217 dB (best=-20.020196)\n",
      "i=5000   nmse=-20.000193 dB (best=-20.020700)\n",
      "i=6000   nmse=-19.983654 dB (best=-20.020700)\n",
      "i=7000   nmse=-20.000472 dB (best=-20.020700)\n",
      "i=8000   nmse=-20.012021 dB (best=-20.026054)\n",
      "i=9000   nmse=-20.008733 dB (best=-20.030982)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i=10000  nmse=-20.015743 dB (best=-20.030982)\n",
      "i=11000  nmse=-20.010319 dB (best=-20.030982)\n",
      "i=12000  nmse=-20.015428 dB (best=-20.031744)\n",
      "i=13000  nmse=-20.007284 dB (best=-20.037755)\n",
      "i=14000  nmse=-20.032868 dB (best=-20.037755)\n",
      "i=15000  nmse=-19.987128 dB (best=-20.037755)\n",
      "i=16000  nmse=-20.024278 dB (best=-20.037755)\n",
      "i=17000  nmse=-20.001993 dB (best=-20.037755)\n",
      "i=18000  nmse=-20.015213 dB (best=-20.040844)\n",
      "i=19000  nmse=-20.002513 dB (best=-20.040844)\n",
      "i=20000  nmse=-20.007796 dB (best=-20.040844)\n",
      "i=21000  nmse=-19.984659 dB (best=-20.040844)\n",
      "i=22000  nmse=-20.007679 dB (best=-20.040844)\n",
      "i=23000  nmse=-19.978485 dB (best=-20.040844)\n",
      "LISTA T=5 trainrate=0.01 fine tuning all B_0:0,S_0:0,lam_0:0,lam_1:0,lam_2:0,lam_3:0,lam_4:0,lam_5:0\n",
      "i=0      nmse=-19.978485 dB (best=-19.978484)\n",
      "i=1000   nmse=-20.108776 dB (best=-20.108775)\n",
      "i=2000   nmse=-20.131454 dB (best=-20.132696)\n",
      "i=3000   nmse=-20.136368 dB (best=-20.136624)\n",
      "i=4000   nmse=-20.130713 dB (best=-20.136624)\n",
      "i=5000   nmse=-20.132856 dB (best=-20.136702)\n",
      "i=6000   nmse=-20.131223 dB (best=-20.136702)\n",
      "i=7000   nmse=-20.135818 dB (best=-20.137505)\n",
      "i=8000   nmse=-20.136874 dB (best=-20.137932)\n",
      "i=9000   nmse=-20.134339 dB (best=-20.143700)\n",
      "i=10000  nmse=-20.138690 dB (best=-20.143700)\n",
      "i=11000  nmse=-20.139093 dB (best=-20.143700)\n",
      "i=12000  nmse=-20.141549 dB (best=-20.143700)\n",
      "i=13000  nmse=-20.140307 dB (best=-20.147085)\n",
      "i=14000  nmse=-20.139844 dB (best=-20.147085)\n",
      "i=15000  nmse=-20.141366 dB (best=-20.147085)\n",
      "i=16000  nmse=-20.144312 dB (best=-20.147085)\n",
      "i=17000  nmse=-20.138235 dB (best=-20.147085)\n",
      "i=18000  nmse=-20.147407 dB (best=-20.147406)\n",
      "i=19000  nmse=-20.136297 dB (best=-20.147406)\n",
      "i=20000  nmse=-20.139277 dB (best=-20.147406)\n",
      "i=21000  nmse=-20.139744 dB (best=-20.147406)\n",
      "i=22000  nmse=-20.138690 dB (best=-20.147406)\n",
      "i=23000  nmse=-20.142343 dB (best=-20.147406)\n",
      "i=24000  nmse=-20.135345 dB (best=-20.147406)\n",
      "LISTA T=6 extending lam_5:0\n",
      "i=0      nmse=-18.390725 dB (best=-18.390725)\n",
      "i=1000   nmse=-18.998537 dB (best=-18.998549)\n",
      "i=2000   nmse=-18.998226 dB (best=-18.998554)\n",
      "i=3000   nmse=-18.998535 dB (best=-18.998555)\n",
      "i=4000   nmse=-18.998418 dB (best=-18.998555)\n",
      "i=5000   nmse=-18.998415 dB (best=-18.998555)\n",
      "i=6000   nmse=-18.998466 dB (best=-18.998555)\n",
      "i=7000   nmse=-18.998461 dB (best=-18.998555)\n",
      "i=8000   nmse=-18.998550 dB (best=-18.998555)\n",
      "LISTA T=6 trainrate=0.5 fine tuning all B_0:0,S_0:0,lam_0:0,lam_1:0,lam_2:0,lam_3:0,lam_4:0,lam_5:0\n",
      "i=0      nmse=-18.998550 dB (best=-18.998550)\n",
      "i=1000   nmse=-21.357343 dB (best=-21.377412)\n",
      "i=2000   nmse=-21.310534 dB (best=-21.377412)\n",
      "i=3000   nmse=-21.283193 dB (best=-21.377412)\n",
      "i=4000   nmse=-21.229937 dB (best=-21.377412)\n",
      "i=5000   nmse=-21.267841 dB (best=-21.377412)\n",
      "i=6000   nmse=-21.286795 dB (best=-21.377412)\n",
      "LISTA T=6 trainrate=0.1 fine tuning all B_0:0,S_0:0,lam_0:0,lam_1:0,lam_2:0,lam_3:0,lam_4:0,lam_5:0\n",
      "i=0      nmse=-21.286795 dB (best=-21.286793)\n",
      "i=1000   nmse=-22.075012 dB (best=-22.078811)\n",
      "i=2000   nmse=-22.087417 dB (best=-22.097800)\n",
      "i=3000   nmse=-22.077644 dB (best=-22.097800)\n",
      "i=4000   nmse=-22.073312 dB (best=-22.099609)\n",
      "i=5000   nmse=-22.071204 dB (best=-22.099609)\n",
      "i=6000   nmse=-22.054172 dB (best=-22.104531)\n",
      "i=7000   nmse=-22.077978 dB (best=-22.104531)\n",
      "i=8000   nmse=-22.080946 dB (best=-22.106347)\n",
      "i=9000   nmse=-22.066491 dB (best=-22.106347)\n",
      "i=10000  nmse=-22.072036 dB (best=-22.108471)\n",
      "i=11000  nmse=-22.049794 dB (best=-22.108471)\n",
      "i=12000  nmse=-22.083206 dB (best=-22.115776)\n",
      "i=13000  nmse=-22.078509 dB (best=-22.115776)\n",
      "i=14000  nmse=-22.059493 dB (best=-22.115776)\n",
      "i=15000  nmse=-22.034082 dB (best=-22.115776)\n",
      "i=16000  nmse=-22.076378 dB (best=-22.115776)\n",
      "i=17000  nmse=-22.084091 dB (best=-22.125436)\n",
      "i=18000  nmse=-22.088301 dB (best=-22.125436)\n",
      "i=19000  nmse=-22.089102 dB (best=-22.125436)\n",
      "i=20000  nmse=-22.053742 dB (best=-22.125436)\n",
      "i=21000  nmse=-22.088985 dB (best=-22.125436)\n",
      "i=22000  nmse=-22.071307 dB (best=-22.125436)\n",
      "LISTA T=6 trainrate=0.01 fine tuning all B_0:0,S_0:0,lam_0:0,lam_1:0,lam_2:0,lam_3:0,lam_4:0,lam_5:0\n",
      "i=0      nmse=-22.071307 dB (best=-22.071304)\n",
      "i=1000   nmse=-22.240708 dB (best=-22.240706)\n",
      "i=2000   nmse=-22.253895 dB (best=-22.256691)\n",
      "i=3000   nmse=-22.259405 dB (best=-22.261749)\n",
      "i=4000   nmse=-22.260838 dB (best=-22.267894)\n",
      "i=5000   nmse=-22.263763 dB (best=-22.267894)\n",
      "i=6000   nmse=-22.263031 dB (best=-22.267894)\n",
      "i=7000   nmse=-22.264063 dB (best=-22.267894)\n",
      "i=8000   nmse=-22.264311 dB (best=-22.268705)\n",
      "i=9000   nmse=-22.276359 dB (best=-22.276748)\n",
      "i=10000  nmse=-22.268782 dB (best=-22.276748)\n",
      "i=11000  nmse=-22.259791 dB (best=-22.276748)\n",
      "i=12000  nmse=-22.262082 dB (best=-22.276748)\n",
      "i=13000  nmse=-22.265143 dB (best=-22.276748)\n",
      "i=14000  nmse=-22.262933 dB (best=-22.276748)\n"
     ]
    }
   ],
   "source": [
    "ivl, maxit, better_wait =10,1000000,5000\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "print('norms xval:{xval:.7f} yval:{yval:.7f}'.format(xval=la.norm(xval), yval=la.norm(yval) ) )\n",
    "\n",
    "state = load_trainable_vars(sess,'LISTA_bg_giid.npz') # must load AFTER the initializer\n",
    "\n",
    "    # must use this same Session to perform all training\n",
    "    # if we start a new Session, things would replay and we'd be training with our validation set (no no)\n",
    "\n",
    "done=state.get('done',[])\n",
    "log=str(state.get('log',''))\n",
    "\n",
    "for name,xhat_,loss_,nmse_,train_,var_list in training_stages:\n",
    "    if name in done:\n",
    "        print('Already did ' + name + '. Skipping.')\n",
    "        continue\n",
    "    if len(var_list):\n",
    "        describe_var_list = 'extending ' + ','.join([v.name for v in var_list])\n",
    "    else:\n",
    "        describe_var_list = 'fine tuning all ' + ','.join([v.name for v in tf.trainable_variables() ])\n",
    "\n",
    "    print(name + ' ' + describe_var_list)\n",
    "    nmse_history=[]\n",
    "    for i in range(maxit+1):\n",
    "        if i%ivl == 0:\n",
    "            nmse = sess.run(nmse_,feed_dict={y_:yval,x_:xval})\n",
    "            if np.isnan(nmse):\n",
    "                raise RuntimeError('nmse is NaN')\n",
    "            nmse_history = np.append(nmse_history,nmse)\n",
    "            nmse_dB = 10*np.log10(nmse)\n",
    "            nmsebest_dB = 10*np.log10(nmse_history.min())\n",
    "            sys.stdout.write('\\ri={i:<6d} nmse={nmse:.6f} dB (best={best:.6f})'.format(i=i,nmse=nmse_dB,best=nmsebest_dB))\n",
    "            sys.stdout.flush()\n",
    "            if i%(100*ivl) == 0:\n",
    "                print('')\n",
    "                age_of_best = len(nmse_history) - nmse_history.argmin()-1 # how long ago was the best nmse?\n",
    "                if age_of_best*ivl > better_wait:\n",
    "                    break # if it has not improved on the best answer for quite some time, then move along\n",
    "        #y,x = prob(sess)\n",
    "        y, x= sess.run( ( ygen_,xgen_ ) ) # generates different y,x for every iteration.\n",
    "        sess.run(train_,feed_dict={y_:y,x_:x} )\n",
    "    done = np.append(done,name)\n",
    "\n",
    "    log =  log+'\\n{name} nmse={nmse:.6f} dB in {i} iterations'.format(name=name,nmse=nmse_dB,i=i)\n",
    "\n",
    "    state['done'] = done\n",
    "    state['log'] = log\n",
    "    save_trainable_vars(sess,'LISTA_bg_giid.npz',**state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e14c1f",
   "metadata": {},
   "source": [
    "# Testing  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0b07196a",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest = ((np.random.uniform( 0,1,(N,1))<pnz) * np.random.normal(0,1,(N,1))).astype(np.float32)\n",
    "ytest = np.matmul(A,xtest) + np.random.normal(0,math.sqrt( noise_var ),(M,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1f81712e",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for name,xhat_,var_list in layers:\n",
    "    count = count + 1\n",
    "    if count != 7:\n",
    "        continue\n",
    "    else:\n",
    "        out = sess.run(xhat_,feed_dict={y_:ytest,x_:xtest})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "accb1183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xtest= \n",
      " [[-0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [ 0.        ]\n",
      " [-0.25618178]\n",
      " [ 1.114737  ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [-0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.07645008]\n",
      " [ 0.        ]\n",
      " [-0.05123669]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [-0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [-0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [-1.0751579 ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [ 0.        ]\n",
      " [-0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [-0.98249495]\n",
      " [-0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [ 0.        ]\n",
      " [-0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [-0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [-0.        ]\n",
      " [ 0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [ 0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [ 0.        ]\n",
      " [-0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [ 0.        ]\n",
      " [-0.        ]\n",
      " [ 0.08782988]\n",
      " [ 0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [ 0.16218522]\n",
      " [ 0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [ 1.4205736 ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [ 0.        ]\n",
      " [-0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.5920279 ]\n",
      " [-0.        ]\n",
      " [ 0.        ]\n",
      " [-0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.1668923 ]\n",
      " [-0.21677786]\n",
      " [ 0.        ]\n",
      " [-0.1526441 ]\n",
      " [ 0.        ]\n",
      " [-0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.38154823]\n",
      " [ 0.        ]\n",
      " [ 0.328265  ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [ 0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [ 0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [ 0.        ]\n",
      " [-0.        ]\n",
      " [ 0.        ]\n",
      " [-0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [ 0.        ]\n",
      " [-0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [ 0.        ]\n",
      " [-0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [ 0.52528006]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [ 0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [ 0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [ 0.        ]\n",
      " [-0.485499  ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [-0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [ 0.        ]\n",
      " [-0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [ 0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [ 0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [ 1.8060373 ]\n",
      " [-1.0557942 ]\n",
      " [-0.        ]\n",
      " [ 0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [ 0.        ]\n",
      " [-1.1551427 ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [ 0.3390617 ]\n",
      " [-0.        ]\n",
      " [ 0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [-1.517813  ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [-0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [-0.        ]\n",
      " [ 0.05015058]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [-0.25834686]\n",
      " [-0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [-0.        ]\n",
      " [ 0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [-0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [-0.        ]\n",
      " [ 0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [-0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [-0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [-0.        ]\n",
      " [ 0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [ 0.        ]\n",
      " [-0.        ]\n",
      " [ 0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [ 1.9071727 ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [-2.5269687 ]\n",
      " [ 0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [-0.        ]\n",
      " [ 0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.33930874]\n",
      " [-0.        ]\n",
      " [ 0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [ 0.        ]\n",
      " [-0.        ]\n",
      " [-0.59211075]\n",
      " [ 0.        ]\n",
      " [-0.        ]\n",
      " [ 0.        ]\n",
      " [-0.08852943]\n",
      " [ 0.        ]\n",
      " [-0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.38676354]\n",
      " [ 0.        ]\n",
      " [-0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [-0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [ 0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 2.0710733 ]\n",
      " [-0.        ]\n",
      " [ 0.        ]\n",
      " [-0.        ]\n",
      " [ 0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [ 0.        ]\n",
      " [-1.5558387 ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [-0.7454461 ]\n",
      " [ 0.90973014]\n",
      " [ 0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [ 0.2450026 ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [-0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [-0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [ 0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [ 0.41453147]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [-0.        ]\n",
      " [ 0.        ]\n",
      " [-0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [-0.44193542]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [-0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [-1.1370543 ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [-0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [-0.5525996 ]\n",
      " [ 0.        ]\n",
      " [-0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [-0.54933095]\n",
      " [ 0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [ 0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [ 2.1652262 ]\n",
      " [-0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [-0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [-0.        ]\n",
      " [ 0.        ]\n",
      " [-0.        ]\n",
      " [-1.4229494 ]]\n",
      "estimated out \n",
      " [[ 0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [-1.61488757e-01]\n",
      " [ 1.07937574e+00]\n",
      " [ 0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [ 9.72434580e-02]\n",
      " [ 0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [-2.45988257e-02]\n",
      " [-0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [ 1.07056983e-02]\n",
      " [-0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [-1.00481200e+00]\n",
      " [ 3.83794308e-04]\n",
      " [-0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [-9.22157228e-01]\n",
      " [-0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [ 2.41284259e-02]\n",
      " [ 0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-1.34215616e-02]\n",
      " [ 1.21615574e-01]\n",
      " [ 0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [ 3.72033529e-02]\n",
      " [-0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [-9.38897207e-03]\n",
      " [ 0.00000000e+00]\n",
      " [ 1.49279022e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [ 6.22379124e-01]\n",
      " [ 0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 9.36630219e-02]\n",
      " [-1.27182886e-01]\n",
      " [-0.00000000e+00]\n",
      " [-6.56717867e-02]\n",
      " [ 0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 3.76069486e-01]\n",
      " [-0.00000000e+00]\n",
      " [ 2.72588193e-01]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 3.68960388e-02]\n",
      " [-4.17545848e-02]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 5.28820232e-03]\n",
      " [ 0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 4.82110679e-01]\n",
      " [-0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-7.85369053e-03]\n",
      " [ 2.63904408e-03]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [-1.05766989e-02]\n",
      " [-0.00000000e+00]\n",
      " [-4.45419669e-01]\n",
      " [-0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [ 2.37926431e-02]\n",
      " [ 4.46815044e-04]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [ 1.18881650e-02]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-1.90815218e-02]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-6.73126057e-03]\n",
      " [ 0.00000000e+00]\n",
      " [ 1.83453882e+00]\n",
      " [-9.95262921e-01]\n",
      " [ 0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [-1.14633453e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [ 2.55603611e-01]\n",
      " [ 0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-1.50925779e+00]\n",
      " [ 0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-3.44375148e-03]\n",
      " [ 0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 2.53938325e-02]\n",
      " [-0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [-2.41779491e-01]\n",
      " [-0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [ 9.41603258e-03]\n",
      " [-0.00000000e+00]\n",
      " [-2.85320915e-02]\n",
      " [ 0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-4.93671373e-03]\n",
      " [ 1.76205225e-02]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [ 4.39734384e-03]\n",
      " [-0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [ 1.79940946e-02]\n",
      " [ 0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [ 1.98763347e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [-1.73827149e-02]\n",
      " [ 0.00000000e+00]\n",
      " [-8.76311213e-04]\n",
      " [ 0.00000000e+00]\n",
      " [-2.56932425e+00]\n",
      " [ 0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [-1.16064772e-03]\n",
      " [-0.00000000e+00]\n",
      " [ 2.97473744e-03]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-1.00670643e-02]\n",
      " [ 3.30509424e-01]\n",
      " [-0.00000000e+00]\n",
      " [ 5.29985912e-02]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [-5.36633968e-01]\n",
      " [-0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [-4.15099151e-02]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [ 3.75608444e-01]\n",
      " [ 0.00000000e+00]\n",
      " [ 1.97470672e-02]\n",
      " [ 0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 2.08815551e+00]\n",
      " [ 0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [-3.76040824e-02]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [-1.61185956e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-7.26617992e-01]\n",
      " [ 8.26149166e-01]\n",
      " [-8.71795788e-03]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 1.71101481e-01]\n",
      " [-0.00000000e+00]\n",
      " [-6.58117607e-03]\n",
      " [ 0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 4.08441007e-01]\n",
      " [-0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [-2.44102441e-02]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [-4.65164483e-01]\n",
      " [-0.00000000e+00]\n",
      " [ 1.50238462e-02]\n",
      " [ 0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-1.12346005e+00]\n",
      " [ 0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-4.82245028e-01]\n",
      " [ 0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 7.07464069e-02]\n",
      " [ 0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-5.65968692e-01]\n",
      " [-0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [ 3.09315696e-03]\n",
      " [ 0.00000000e+00]\n",
      " [ 2.17566895e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-1.39368248e+00]]\n"
     ]
    }
   ],
   "source": [
    "print('xtest= \\n',xtest)\n",
    "print('estimated out \\n', out)        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4abf0e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
